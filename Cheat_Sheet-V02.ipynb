{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kevin's Pandas' Crib Sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a consolidation notes and examples from:\n",
    "> Coreys MSchafer's Pandas videos [here](https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS) \n",
    "\n",
    "and \n",
    "> Hands on Data Analysis by xxx\n",
    "\n",
    "Version 2.0W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set-Up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Dataset Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Functions that create Example Datasets for use later \n",
    "\n",
    "def mk_dictionary(x):\n",
    "    if x == \"people\":\n",
    "        dictionary = {\n",
    "            'first': ['Corey', 'Jane', 'Janey', 'John', 'Jimmy'], \n",
    "            'last': ['Schafer', 'Doe', 'Doe', 'Doe', 'Doe'], \n",
    "            'email': [\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JaneyDoe@email.com','JohnDoe@email.com', 'JimmyDoe@email.com']\n",
    "        }\n",
    "    elif x == 'people2':\n",
    "        dictionary = {\n",
    "            'first': ['Tony', 'Steve'], \n",
    "            'last': ['Stark', 'Rogers'], \n",
    "            'email': ['IronMan@avenge.com', 'Cap@avenge.com']\n",
    "        }\n",
    "    \n",
    "    return dictionary \n",
    "\n",
    "def mk_dataframe(x):\n",
    "    if x == \"people\":\n",
    "        df =  pd.DataFrame(mk_dictionary('people'))\n",
    "    elif x == \"people2\":\n",
    "        df =  pd.DataFrame(mk_dictionary('people2'))\n",
    "    return df\n",
    "\n",
    "# test_dictionary = mk_dictionary('people')\n",
    "# test_dictionary = mk_dictionary('people2')\n",
    "# test_dictionary\n",
    "\n",
    "# df = mk_dataframe('people')\n",
    "# df = mk_dataframe('people2')\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Bad Chp3 Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = {'date': {0: '2018-01-01T00:00:00',\n",
    "  1: '2018-01-01T00:00:00',\n",
    "  2: '2018-01-01T00:00:00',\n",
    "  3: '2018-01-02T00:00:00',\n",
    "  4: '2018-01-03T00:00:00',\n",
    "  5: '2018-01-03T00:00:00',\n",
    "  6: '2018-01-03T00:00:00',\n",
    "  7: '2018-01-04T00:00:00',\n",
    "  8: '2018-01-04T00:00:00',\n",
    "  9: '2018-01-05T00:00:00'},\n",
    " 'station': {0: '?',\n",
    "  1: '?',\n",
    "  2: '?',\n",
    "  3: 'GHCND:USC00280907',\n",
    "  4: 'GHCND:USC00280907',\n",
    "  5: 'GHCND:USC00280907',\n",
    "  6: 'GHCND:USC00280907',\n",
    "  7: '?',\n",
    "  8: '?',\n",
    "  9: '?'},\n",
    " 'PRCP': {0: 0.0,\n",
    "  1: 0.0,\n",
    "  2: 0.0,\n",
    "  3: 0.0,\n",
    "  4: 0.0,\n",
    "  5: 0.0,\n",
    "  6: 0.0,\n",
    "  7: 20.6,\n",
    "  8: 20.6,\n",
    "  9: 0.3},\n",
    " 'SNOW': {0: 0.0,\n",
    "  1: 0.0,\n",
    "  2: 0.0,\n",
    "  3: 0.0,\n",
    "  4: 0.0,\n",
    "  5: 0.0,\n",
    "  6: 0.0,\n",
    "  7: 229.0,\n",
    "  8: 229.0,\n",
    "  9: 'nan'},\n",
    " 'SNWD': {0: '-inf',\n",
    "  1: '-inf',\n",
    "  2: '-inf',\n",
    "  3: '-inf',\n",
    "  4: '-inf',\n",
    "  5: '-inf',\n",
    "  6: '-inf',\n",
    "  7: 'inf',\n",
    "  8: 'inf',\n",
    "  9: 'nan'},\n",
    " 'TMAX': {0: 5505.0,\n",
    "  1: 5505.0,\n",
    "  2: 5505.0,\n",
    "  3: -8.3,\n",
    "  4: -4.4,\n",
    "  5: -4.4,\n",
    "  6: -4.4,\n",
    "  7: 5505.0,\n",
    "  8: 5505.0,\n",
    "  9: 5505.0},\n",
    " 'TMIN': {0: -40.0,\n",
    "  1: -40.0,\n",
    "  2: -40.0,\n",
    "  3: -16.1,\n",
    "  4: -13.9,\n",
    "  5: -13.9,\n",
    "  6: -13.9,\n",
    "  7: -40.0,\n",
    "  8: -40.0,\n",
    "  9: -40.0},\n",
    " 'TOBS': {0: 'nan',\n",
    "  1: 'nan',\n",
    "  2: 'nan',\n",
    "  3: -12.2,\n",
    "  4: -13.3,\n",
    "  5: -13.3,\n",
    "  6: -13.3,\n",
    "  7: 'nan',\n",
    "  8: 'nan',\n",
    "  9: 'nan'},\n",
    " 'WESF': {0: 'nan',\n",
    "  1: 'nan',\n",
    "  2: 'nan',\n",
    "  3: 'nan',\n",
    "  4: 'nan',\n",
    "  5: 'nan',\n",
    "  6: 'nan',\n",
    "  7: 19.3,\n",
    "  8: 19.3,\n",
    "  9: 'nan'},\n",
    " 'inclement_weather': {0: 'nan',\n",
    "  1: 'nan',\n",
    "  2: 'nan',\n",
    "  3: False,\n",
    "  4: False,\n",
    "  5: False,\n",
    "  6: False,\n",
    "  7: True,\n",
    "  8: True,\n",
    "  9: 'nan'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Making a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.DataFrame(people)\n",
    "df2 = pd.DataFrame(people2)\n",
    "# bad_df = pd.DataFrame(bad_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Overview of the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()             # Overview of the dataframe\n",
    "# df.columns            # List column names\n",
    "# df.head(10)           # List top x rows (default is 5)\n",
    "# df.tail()             # List bottom x rows (default is 5)\n",
    "# df.sample()           # List randon x rows (default is 1)\n",
    "# df.describe()         # Quick summart of the frame, best for wide format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a new index. Keep it set with `inplace``.  \n",
    "# Indexes don't have to be unique\n",
    "df.set_index('email', inplace=True)     # Set a column to be an index\n",
    "print(df.index)\n",
    "df.reset_index(inplace=True)            # Reset row indexes to (hand to 'save'a column used a an index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accessing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df                                # Simple access\n",
    "# df['email']                       # Access single column\n",
    "# df[['last', 'email']]             # Access multiple columns by using a list (a list within the list)i\n",
    "\n",
    "# df.iloc[[0, 1], 2]                # Access by integer reference / index by using .iloc.  .loc and iloc takes row index first\n",
    "\n",
    "# df.loc['CoreyMSchafer@gmail.com', 'last'] # Access by row index name .loc\n",
    "# df.loc[[0, 1], ['email', 'last']] # As above plus selected columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selecting Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Filters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best to filter with 2 part process:\n",
    "1. Set filter \n",
    "2. Apply filter\n",
    "\n",
    "_But can't use word \"filter\" as a variable name it's reserved_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df['last'] == 'Schafer') | (df['first'] == 'John')  # 1) Set filter.  An exampe of an 'or' '|' filter\n",
    "df.loc[filt, 'email']                                       # 2) Apply filter or\n",
    "# df.loc[~filt, 'email']                                    # 2) Apply inverse of filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Updating Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Update Column Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = ['email', 'first_name', 'last_name']         # Rename all columns \n",
    "\n",
    "# df.rename(                                                # Rename specific columns using .rename\n",
    "#     columns={\n",
    "#         'first_name': 'first', 'last_name': 'last'\n",
    "#         }, inplace=True                                   # Note, need \"inplace\" \n",
    "#     ) \n",
    " \n",
    "# df.columns = [x.upper() for x in df.columns]              # Rename all columns by an inline comprehension .columns\n",
    "\n",
    "# Reset\n",
    "df.columns = [x.lower() for x in df.columns]                # Reset so later examples work\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Update Values - Direct Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email'] = df['email'].str.lower()                               # Update whole column with string object method with.str.x\n",
    "df.loc[3] = ['John2Smith@email.com', 'John2', 'Smith']              # Update whole row with .loc\n",
    "df.loc[2, ['last', 'email']] = ['Smith', 'janeysmith@email.com']    # Update specific columns of a row with .loc\n",
    "\n",
    "# Update based on filter \n",
    "filt = (df['email'] == 'John2Smith@email.com')                      # Update cells based on a filter with .loc\n",
    "# df[filt]['last'] = 'Smith'                                        # DON'T do this, it won't work\n",
    "df.loc[filt, 'first'] = 'Johnny'                                    # THIS will, need .loc\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Updating Values - with Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four Functions:\n",
    "- `apply`\n",
    "- `map`\n",
    "- `applymap` &\n",
    "- `replace`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 `apply` a function to an object (dataframe or series) and get a series as a result\n",
    "- Object can be a series (by default a column) \n",
    "- Object can be a dataframe in which case it's applied to each series (column) for a single result for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying to a column\n",
    "# df['email'].apply(len)            # `apply` the `len` function to the email column\n",
    "\n",
    "# def update_email(email):          # 'apply' your own function\n",
    "#     return email.upper()\n",
    "# df['email'].apply(update_email) \n",
    "\n",
    "# df['email'].apply(                # 'Apply' a your own inline (LAMBDA) function \n",
    "#     lambda x: x.lower()           # to a whole column and get a series as a result\n",
    "#     )  \n",
    "\n",
    "# When applied to a dataframe 'apply' is applied across each series\n",
    "df.apply(len) # or df.apply(len, axis='columns') or df.apply(len, axis='rows')   \n",
    "# df.apply(pd.Series.min)           # Returns the minimum (first in alaphs) in each column\n",
    "\n",
    "# df.apply(                           # Applying a Lambda function to each series\n",
    "#     lambda x: x.min()\n",
    "#     )     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 `applymap` a function to a dataframe and get a dataframe as a result.  \n",
    "Applied elementwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.applymap(len)\n",
    "df.applymap(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 `map` a series and get a series as a result.  \n",
    "Replaces __all__ elements in series  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .map only works on a series. Use like a vlookup\n",
    "# Use it to subsitute one value for another via a lookup dictionary.\n",
    "# Unsubtituted vales replaced by NaN\n",
    "df['first'].map({'Corey': 'Chris', 'Jane': 'Mary'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.4 `replace` a series and get series result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .replace works like map but leaves unsubsittuted values untouched (not NaN)\n",
    "df['first'] = df['first'].replace({'Corey': 'Corey2', 'Jane': 'Jane2'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Updating Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't use . notation as pandas would look for method\n",
    "\n",
    "# Create multiple columns at once \n",
    "# df[['first', 'last']] = df['full_name'].str.split(' ', expand=True)\n",
    "\n",
    "# Creating a new column with strings, can use numeric as well with .apply \n",
    "df['full_name'] = df['first'] + ' ' + df['last']\n",
    "\n",
    "# Split data with str.split.  Splits on space by default so not needed\n",
    "# would give list by default, need expand=True to make 2 new columns in dataframe\n",
    "df['full_name'].str.split(' ', expand=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with .drop like a db\n",
    "df.drop(columns=['first', 'last'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 Adding Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a single row with .append\n",
    "# df.append({'first': 'Tony'}, ignore_index=True) # insert new row even if no index given: ignore_index=True\n",
    "\n",
    "# Now deprecated:\n",
    "df2 = pd.DataFrame({'first': ['Tony']})\n",
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 Dropping Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=3, inplace=True)              # Deleteing a row with .drop\n",
    "\n",
    "filt = df['full_name'] == 'Jane2 Doe'                # Dropping rows based on values.  This case index\n",
    "df.drop(index=df[filt].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows based on values \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df, df2], ignore_index=True, sort=False) # Adding a whole new dataframe as new rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Sort a Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email'].sort_values()    # Sort a series (column) with .sort_values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Sort a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by='email', ascending=False)   # Sort a dataframe by a single column with sort_values\n",
    "\n",
    "df.sort_values(                                 # Sort a dataframe by a multiple columnsin a list with .sort_values\n",
    "    by=['email', 'full_name'], \n",
    "    ascending=False)  \n",
    "\n",
    "# df.sort_values(                               # Sort a dataframe by a multiple columns in a list with .sort_values \n",
    "#     by=['email', 'full_name'],                # and different asending attrbutes from a list and make perm with inpace \n",
    "#     ascending=[False, True], \n",
    "#     inplace=True  \n",
    "#     )\n",
    "\n",
    "df.sort_index()                               # Reset the order based on the \"original\" index with .sort_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates_df[[\n",
    "#     'numeric_data_01', 'numeric_data_02']].median() # use aggregation functuins, such as mean, mode, standard deviation etc on a simgle column\n",
    "\n",
    "# aggregates_df['numeric_data_01'].count()            # count the number of populated fields in a column with .count\n",
    "\n",
    "# aggregates_df['numeric_data_01'].value_counts()     # count the number of eachvalue with .value_counts \n",
    "\n",
    "aggregates_df['numeric_data_01'].value_counts(        # or to get a percentage use the normalise=True attribute\n",
    "    normalize=True)*100                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a group in a similar way as we created a filter, but with .groupby([column_name])\n",
    "# This gives you a group object, indexed by the group rather than true / galse list of a filter\n",
    "grp_last = df.groupby(['last'])\n",
    "grp_last.groups                # KT added to see groups and indexes\n",
    "\n",
    "# Then apply methods to the group in a 2nd step, e.g., .get_group \n",
    "grp_last.get_group('Smith')\n",
    "\n",
    "# Apply a function (.value_counts) to a column after already being grouped\n",
    "# Can filter furtther with .loc makes it loke usiong a filter\n",
    "# Can also get percentage like above with (normalize=True)*100\n",
    "grp_last['first'].value_counts() #.loc['Smith']\n",
    "\n",
    "# Can retrive multiple columns and perform other aggregate functions with their methods \n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].median() #.loc[['Smith' , 'Doe']]\n",
    "\n",
    "# *** Or use more generic form to apply multiple aggregated functions with .agg ***\n",
    "# Seems most generic to me!!!\n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].agg(['count', 'mean', 'std']) #.loc[['Smith' , 'Doe']]\n",
    "\n",
    "# Counting rows with filter.  Counts true's in the returned series with .sum\n",
    "filt = df['last'] == 'Doe'\n",
    "df.loc[filt]['first'].str.contains('Jane').sum()\n",
    "\n",
    "# But fora group need to .apply the function to all the group's series \n",
    "grp_last['first'].apply(lambda x: x.str.contains('n').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the percentage with an n in their first name and group by surname\n",
    "\n",
    "# Create a series of the number of people with each surname\n",
    "surname_count = df['last'].value_counts()\n",
    "surname_count\n",
    "\n",
    "# Create a series of people with each surname, with 'n' in first name\n",
    "surname_count_with_n = grp_last['first'].apply(lambda x: x.str.contains('n').sum())\n",
    "surname_count_with_n\n",
    "\n",
    "# Merge the 2 series togther, add and calculate the percentage (answer column) and tidy up column names\n",
    "df_with_n = pd.concat([surname_count, surname_count_with_n], axis='columns', sort=False)\n",
    "df_with_n['percentage'] = df_with_n['first']/df_with_n['last']*100\n",
    "df_with_n.rename(columns={'first': 'First_with_an_n', 'last': 'Surname'}, inplace=True)\n",
    "df_with_n.sort_values('percentage', ascending=False)\n",
    "# df_with_n.loc['Smith']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up some dirty data  \n",
    "people = {\n",
    "    'first': ['Corey', 'Jane', 'John', 'Chris', np.nan, None, 'NA'], \n",
    "    'last': ['Schafer', 'Doe', 'Doe', 'Schafer', np.nan, np.nan, 'Missing'], \n",
    "    'email': ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com', None, np.nan, 'Anonymous@email.com', 'NA'],\n",
    "    'age': ['33', '55', '63', '36', None, None, 'Missing']\n",
    "}\n",
    "df = pd.DataFrame(people)\n",
    "df\n",
    "# GOOD IDEA look for unique values in columns to see if you're likely to get problems \n",
    "# for i in df.columns:\n",
    "#     print(f'\\n{i}')\n",
    "#     print(df[i].unique())\n",
    "\n",
    "# Identify na values (by getting a mask) rather than drop them with .isna\n",
    "df.isna()\n",
    "# or\n",
    "df.isna().sum()\n",
    "\n",
    "# Cleaning. Replace unusual nill values across whole data frame\n",
    "# Could do all this at import time for csv pd.read_csv(XXXXX..., na_values=['NA','Missing'])\n",
    "df.replace('NA', np.nan, inplace=True)\n",
    "df.replace('Missing', np.nan, inplace=True)\n",
    "df\n",
    "\n",
    "# Cleaning. Replaces NaN values with an actual value.  Most usful for NUMERIC data\n",
    "df.fillna(0)\n",
    "\n",
    "# Drop any / all rows that aren't totally complete with .dropna & how = 'any'\n",
    "# default values are: df.dropna(axis='index', how='any')\n",
    "df.dropna()\n",
    "\n",
    "# Drop incomplete columns.  Which is all of them due to row 4\n",
    "df.dropna(axis='columns')\n",
    "\n",
    "# Drop rows that have missing data in either ('any') specified rows with how='' & subset=[]\n",
    "df.dropna(axis='index', how='any', subset=['last', 'email'])\n",
    "\n",
    "# Identify if data type is correct.  If numeric are wrong many aggrate functions won't work \n",
    "df.dtypes\n",
    "\n",
    "# Cleaning. Casting a column to the correct data type with .astype\n",
    "# Can use .astype on whole dataframe too.\n",
    "# Use float not int, as NaN is a float.\n",
    "df['age'] = df['age'].astype(float)\n",
    "df.dtypes\n",
    "# df['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesson 10 - Date Time Series\n",
    "# Can use ,format= if .to_datetime doesn't auto recognise the date / time format\n",
    "df = pd.read_csv('time_series.csv')\n",
    "df['Date']=pd.to_datetime(df['Date'], format='%Y-%m-%d %I-%p')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find day name for single cell with .day_name() method\n",
    "df.loc[0, 'Date'].day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column comtaining day name with .dt.day_name()\n",
    "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some date functions\n",
    "print(df['Date'].min())\n",
    "print(df['Date'].max())\n",
    "print(df['Date'].max() - df['Date'].min()) # Known as time delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering on date range in str converted to a datetime with .to_datetime\n",
    "filt = (df['Date'] >= pd.to_datetime('2019-01-01')) & (df['Date'] < pd.to_datetime('2020-01-01'))\n",
    "df.loc[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting date column as an index for later functions\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single value slice on index with .loc\n",
    "df.loc['2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice on index with .loc and for range :\n",
    "df.loc['2020-01':'2020-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an aggregate value (eg mean or max) of a column sliced by date \n",
    "print(  df.loc['2020-01':'2020-02']['Close'].mean() )\n",
    "print(  df.loc['2020-01-01']['High'].max()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample (downsample) a range using 'D' for day and .resample\n",
    "highs = df['High'].resample('D').max()\n",
    "highs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick line plot with mathplot & a Magic command needed for Jupyter notebook\n",
    "%matplotlib inline \n",
    "highs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample whole dataframe with single aggregation method\n",
    "df.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample whole dataframe with diferent aggregations with a map & .agg method\n",
    "df.resample('W').agg({'Close': 'mean', 'High': 'max', 'Low': 'min', 'Volume': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX.  To File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Chap 3 Section 5\n",
    "Cleaning, handling duplicate, missing or invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()           # Will show missing values (nulls) and data types\n",
    "# df.describe()       # This will show some errors up in the dataset, eg unreasonably large or small\n",
    "\n",
    "pd.DataFrame({      # Really nice way to gather summary stats for targeted rows into a data frame\n",
    "    'np.inf Snow Depth': df[df.SNWD == np.inf].SNOW.describe(),\n",
    "    '-np.inf Snow Depth': df[df.SNWD == -np.inf].SNOW.describe()\n",
    "}).T                # Note the .T to transpose the results\n",
    "\n",
    "df.describe(include='object')   # Check the descripbe for datetime and others\n",
    "\n",
    "df[df.duplicated(['date', 'station'])]  # Returns the rows (after the first) that \n",
    "                                        # are duplicated in the columns mentioned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3abd6171fa1ea65bf49371a625e2f428f7c9851bddb54635de65591e57828a17"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('c3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
