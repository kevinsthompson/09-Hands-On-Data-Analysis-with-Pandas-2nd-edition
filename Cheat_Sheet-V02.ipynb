{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kevin's Pandas' Crib Sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a consolidation notes and examples from:\n",
    "> Coreys MSchafer's Pandas videos [here](https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS) \n",
    "\n",
    "and \n",
    "> Hands on Data Analysis by Stefanie Molin\n",
    "All data in examples and exercises available [here](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition)\n",
    "\n",
    "Version 2.1W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set-Up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Main Dataset Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Functions that create Example Datasets for use later \n",
    "\n",
    "def mk_dictionary(x):\n",
    "    if x == \"people\":\n",
    "        dictionary = {\n",
    "            'first': ['Corey', 'Jane', 'Janey', 'John', 'Jimmy'], \n",
    "            'last': ['Schafer', 'Doe', 'Doe', 'Doe', 'Doe'], \n",
    "            'email': [\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JaneyDoe@email.com','JohnDoe@email.com', 'JimmyDoe@email.com']\n",
    "        }\n",
    "    elif x == 'people2':\n",
    "        dictionary = {\n",
    "            'first': ['Tony', 'Steve'], \n",
    "            'last': ['Stark', 'Rogers'], \n",
    "            'email': ['IronMan@avenge.com', 'Cap@avenge.com']\n",
    "        }\n",
    "    # Set-up some dirty data  \n",
    "    elif x == \"dirty\":\n",
    "        dictionary = {\n",
    "            'first': ['Corey', 'Jane', 'John', 'Chris', np.nan, None, 'NA'], \n",
    "            'last': ['Schafer', 'Doe', 'Doe', 'Schafer', np.nan, np.nan, 'Missing'], \n",
    "            'email': ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com', None, np.nan, 'Anonymous@email.com', 'NA'],\n",
    "            'age': ['33', '55', '63', '36', None, None, 'Missing']\n",
    "        }\n",
    "    else:\n",
    "        print(f'!!!!! mk_dictionary called wih invalid parameter !!!!')\n",
    "        raise SystemExit\n",
    "    return dictionary \n",
    "\n",
    "def mk_dataframe(x):\n",
    "    df =  pd.DataFrame(mk_dictionary(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "# people  = mk_dictionary('people')\n",
    "# people2 = mk_dictionary('people2')\n",
    "\n",
    "# df = mk_dataframe('people')\n",
    "# df2 = mk_dataframe('people2')\n",
    "# dirty_df = mk_dataframe('dirty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Bad Data for Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff in here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 DateTime Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_datetime_dataframe():\n",
    "  datetime_df = pd.DataFrame(\n",
    "    {'Date': {0: ('2020-03-13 20:00:00'),\n",
    "      1: ('2020-03-13 19:00:00'),\n",
    "      2: ('2020-03-13 18:00:00'),\n",
    "      3: ('2020-03-13 17:00:00'),\n",
    "      4: ('2020-03-13 16:00:00'),\n",
    "      5: ('2020-03-13 15:00:00')},\n",
    "    'Symbol': {0: 'ETHUSD',\n",
    "      1: 'ETHUSD',\n",
    "      2: 'ETHUSD',\n",
    "      3: 'ETHUSD',\n",
    "      4: 'ETHUSD',\n",
    "      5: 'ETHUSD'},\n",
    "    'Open': {0: 129.94, 1: 119.51, 2: 124.47, 3: 124.08, 4: 124.85, 5: 128.39},\n",
    "    'High': {0: 131.82, 1: 132.02, 2: 124.85, 3: 127.42, 4: 129.51, 5: 128.9},\n",
    "    'Low': {0: 126.87, 1: 117.1, 2: 115.5, 3: 121.63, 4: 120.17, 5: 116.06},\n",
    "    'Close': {0: 128.71, 1: 129.94, 2: 119.51, 3: 124.47, 4: 124.08, 5: 124.85},\n",
    "    'Volume': {0: 1940673.93,\n",
    "      1: 7579741.09,\n",
    "      2: 4898735.81,\n",
    "      3: 2753450.92,\n",
    "      4: 4461424.71,\n",
    "      5: 7378976.0}}\n",
    "  )\n",
    "  datetime_df['Date'] = pd.to_datetime(datetime_df['Date'])\n",
    "  datetime_df.set_index('Date', inplace=True)       # Setting date column as an index for later functions\n",
    "  datetime_df.index\n",
    "  return datetime_df\n",
    "\n",
    "\n",
    "datetime_df = mk_datetime_dataframe()\n",
    "datetime_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Making a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "      <th>numeric_data_01</th>\n",
       "      <th>numeric_data_02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "      <td>47</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "      <td>46</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first     last                    email  numeric_data_01  numeric_data_02\n",
       "0    Corey  Schafer  CoreyMSchafer@gmail.com               76               16\n",
       "1     Jane      Doe        JaneDoe@email.com               47               70\n",
       "2    Janey      Doe       JaneyDoe@email.com               76               23\n",
       "3     John      Doe        JohnDoe@email.com               26                6\n",
       "4    Jimmy      Doe       JimmyDoe@email.com               46               87\n",
       "..     ...      ...                      ...              ...              ...\n",
       "120    NaN      NaN                      NaN                9               65\n",
       "121    NaN      NaN                      NaN               29                6\n",
       "122    NaN      NaN                      NaN                7               90\n",
       "123    NaN      NaN                      NaN               80                1\n",
       "124    NaN      NaN                      NaN               81               56\n",
       "\n",
       "[125 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.DataFrame(people)                  # Making a dataframe from a dictionary\n",
    "# df2 = pd.DataFrame(people2)                 # These are used on Corry's examples later\n",
    "# dirty_df = mk_dataframe('dirty')            # These are used on Corry's examples later\n",
    "# Load csv in here? bad_df = pd.DataFrame(bad_data)\n",
    "\n",
    "# Add new columns\n",
    "aggregates_df = pd.DataFrame()              \n",
    "aggregates_df['numeric_data_01'] = \\\n",
    "    np.random.randint(0,100, 125)           # These one is needed for the aggregate examples later\n",
    "aggregates_df['numeric_data_02'] = \\\n",
    "    np.random.randint(0,100, size=len(aggregates_df))\n",
    "\n",
    "# Add a whole new dataframe as new rows\n",
    "pd.concat([df, aggregates_df], axis=1)      # Merges the 2 dataframes alomng the column (#1) axis \n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Overview of the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()             # Overview of the dataframe\n",
    "# df.columns            # List column names\n",
    "# df.head(10)           # List top x rows (default is 5)\n",
    "# df.tail()             # List bottom x rows (default is 5)\n",
    "# df.sample()           # List randon x rows (default is 1)\n",
    "# df.describe()         # Quick summart of the frame, best for wide format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JaneyDoe@email.com',\n",
      "       'JohnDoe@email.com', 'JimmyDoe@email.com'],\n",
      "      dtype='object', name='email')\n",
      "                         first     last\n",
      "email                                  \n",
      "CoreyMSchafer@gmail.com  Corey  Schafer\n",
      "JaneDoe@email.com         Jane      Doe\n",
      "JaneyDoe@email.com       Janey      Doe\n",
      "JohnDoe@email.com         John      Doe\n",
      "JimmyDoe@email.com       Jimmy      Doe\n"
     ]
    }
   ],
   "source": [
    "df = mk_dataframe('people')\n",
    "# Set a new index. Keep it set with `inplace``.  \n",
    "# Indexes don't have to be unique\n",
    "df.set_index('email', inplace=True)     # Set a column to be an index\n",
    "print(df.index)\n",
    "print(df)\n",
    "\n",
    "df.reset_index(inplace=True)            # Reset row indexes to (hand to 'save'a column used a an index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accessing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Access Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                    email\n",
       "0  Corey  Schafer  CoreyMSchafer@gmail.com\n",
       "1   Jane      Doe        JaneDoe@email.com\n",
       "2  Janey      Doe       JaneyDoe@email.com\n",
       "3   John      Doe        JohnDoe@email.com\n",
       "4  Jimmy      Doe       JimmyDoe@email.com"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mk_dataframe('people')\n",
    "df                                # Simple access\n",
    "# df['email']                       # Access single column\n",
    "# df[['last', 'email']]             # Access multiple columns by using a list (a list within the list)i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Access Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mk_dataframe('people')             #Setup\n",
    "df.set_index('email', inplace=True)     #Setup\n",
    "# df.iloc[[0, 1], 2]                    # Access by integer reference / index by using .iloc.  \n",
    "                                        # .loc and iloc takes row index first\n",
    "\n",
    "# df.loc[                               # Access by row index name .loc\n",
    "#     'CoreyMSchafer@gmail.com', 'last']   \n",
    "\n",
    "# df.loc[                               # As above plus multi selected rows and columns \n",
    "#     ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com'], \n",
    "#     ['first', 'last']]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selecting Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Filters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best to filter with 2 part process:\n",
    "1. Set filter \n",
    "2. Apply filter\n",
    "\n",
    "_But can't use word \"filter\" as a variable name it's reserved_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email\n",
       "CoreyMSchafer@gmail.com    Schafer\n",
       "JohnDoe@email.com              Doe\n",
       "Name: last, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mk_dataframe('people')             #Setup\n",
    "df.set_index('email', inplace=True)     #Setup\n",
    "\n",
    "filt = (df['last'] == 'Schafer') |(   # 1) Set filter.  An exampe of an 'or' '|' filter\n",
    "    df['first'] == 'John') \n",
    "df.loc[filt, 'last']                  # 2) Apply filter or\n",
    "# df.loc[~filt, 'last']                 # 2) Apply inverse of filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Updating Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Update Column Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = ['email', 'first_name', 'last_name']         # Rename all columns \n",
    "\n",
    "# df.rename(                                                # Rename specific columns using .rename\n",
    "#     columns={\n",
    "#         'first_name': 'first', 'last_name': 'last'\n",
    "#         }, inplace=True                                   # Note, need \"inplace\" \n",
    "#     ) \n",
    " \n",
    "# df.columns = [x.upper() for x in df.columns]              # Rename all columns by an inline comprehension .columns\n",
    "\n",
    "# Reset\n",
    "df.columns = [x.lower() for x in df.columns]                # Reset so later examples work\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Update Values - Direct Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email'] = df['email'].str.lower()                               # Update whole column with string object method with.str.x\n",
    "df.loc[3] = ['John2Smith@email.com', 'John2', 'Smith']              # Update whole row with .loc\n",
    "df.loc[2, ['last', 'email']] = ['Smith', 'janeysmith@email.com']    # Update specific columns of a row with .loc\n",
    "\n",
    "# Update based on filter \n",
    "filt = (df['email'] == 'John2Smith@email.com')                      # Update cells based on a filter with .loc\n",
    "# df[filt]['last'] = 'Smith'                                        # DON'T do this, it won't work\n",
    "df.loc[filt, 'first'] = 'Johnny'                                    # THIS will, need .loc\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Updating Values - with Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four Functions:\n",
    "- `apply`\n",
    "- `applymap` \n",
    "- `map`\n",
    "- `replace`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 `apply` a function to an object (dataframe or series) and get a series as a result\n",
    "- Object can be a series (by default a column) \n",
    "- Object can be a dataframe in which case it's applied to each series (column) for a single result for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying to a column\n",
    "# df['email'].apply(len)            # `apply` the `len` function to the email column\n",
    "\n",
    "# def update_email(email):          # 'apply' your own function\n",
    "#     return email.upper()\n",
    "# df['email'].apply(update_email) \n",
    "\n",
    "# df['email'].apply(                # 'Apply' a your own inline (LAMBDA) function \n",
    "#     lambda x: x.lower()           # to a whole column and get a series as a result\n",
    "#     )  \n",
    "\n",
    "# When applied to a dataframe 'apply' is applied across each series\n",
    "df.apply(len) # or df.apply(len, axis='columns') or df.apply(len, axis='rows')   \n",
    "# df.apply(pd.Series.min)           # Returns the minimum (first in alaphs) in each column\n",
    "\n",
    "# df.apply(                           # Applying a Lambda function to each series\n",
    "#     lambda x: x.min()\n",
    "#     )     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 `applymap` a function to a dataframe and get a dataframe as a result.  \n",
    "Applied elementwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.applymap(len)\n",
    "df.applymap(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 `map` a series and get a series as a result.  \n",
    "Replaces __all__ elements in series  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .map only works on a series. Use like a vlookup\n",
    "# Use it to subsitute one value for another via a lookup dictionary.\n",
    "# Unsubtituted vales replaced by NaN\n",
    "df['first'].map({'Corey': 'Chris', 'Jane': 'Mary'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.4 `replace` on an object (series or dataframe) a get same object as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .replace works like map but leaves unsubsittuted values untouched (not NaN)\n",
    "df['first'] = df['first'].replace({'Corey': 'Corey2', 'Jane': 'Jane2'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Updating Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't use . notation as pandas would look for method\n",
    "\n",
    "# Split data with str.split.  Splits on space by default so not needed\n",
    "# would give list by default, need expand=True to make 2 new columns in dataframe\n",
    "# df['full_name'].str.split(' ', expand=True)\n",
    "\n",
    "# Creating a new column with strings, can use numeric as well with .apply \n",
    "df['full_name'] = df['first'] + ' ' + df['last']\n",
    "\n",
    "# Create multiple columns at once \n",
    "# df[['first', 'last']] = df['full_name'].str.split(' ', expand=True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with .drop like a db\n",
    "df.drop(columns=['first', 'last'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 Adding Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a single row with .append (Now deprecated)\n",
    "# df.append({'first': 'Tony'}, ignore_index=True) # insert new row even if no index given: ignore_index=True\n",
    "\n",
    "# So use:\n",
    "df2 = pd.DataFrame({'first': ['Tony']})\n",
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 Dropping Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(index=3, inplace=True)                # Deleteing a row with .drop\n",
    "\n",
    "filt = df['full_name'] == 'Jane2 Doe'         # Dropping rows based on values.  This case index\n",
    "# df.drop(index=df[filt].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows based on values \n",
    "# filt = df['last'] == 'Stark'\n",
    "# df.drop(index=df[filt].index)\n",
    "# df.drop(index=df[filt].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df, df2], ignore_index=True, sort=False) # Adding a whole new dataframe as new rows\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Sort a Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email'].sort_values()    # Sort a series (column) with .sort_values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Sort a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by='email', ascending=False)   # Sort a dataframe by a single column with sort_values\n",
    "\n",
    "df.sort_values(                                 # Sort a dataframe by a multiple columnsin a list with .sort_values\n",
    "    by=['email', 'full_name'], \n",
    "    ascending=False)  \n",
    "\n",
    "# df.sort_values(                               # Sort a dataframe by a multiple columns in a list with .sort_values \n",
    "#     by=['email', 'full_name'],                # and different asending attrbutes from a list and make perm with inpace \n",
    "#     ascending=[False, True], \n",
    "#     inplace=True  \n",
    "#     )\n",
    "\n",
    "df.sort_index()                               # Reset the order based on the \"original\" index with .sort_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates_df[[                                     # Use aggregation functuins, such as:\n",
    "#     'numeric_data_01', 'numeric_data_02']].median() # mean, mode, standard deviation on a simgle column\n",
    "\n",
    "# aggregates_df['numeric_data_01'].count()            # count the number of populated fields in a column with .count\n",
    "\n",
    "# aggregates_df['numeric_data_01'].value_counts()     # count the number of eachvalue with .value_counts \n",
    "\n",
    "# aggregates_df['numeric_data_01'].value_counts(        # or to get a percentage use the normalise=True attribute\n",
    "#     normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.0 Reset Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mk_dataframe('people')\n",
    "df = pd.merge(df, aggregates_df, left_index=True, right_index=True)\n",
    "# df = pd.concat([df, aggregates_df], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Working with Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a group in a similar way as we created a filter, but with .groupby([column_name])\n",
    "# This gives you a group object, indexed by the group rather than true / galse list of a filter\n",
    "grp_last = df.groupby(['last'])\n",
    "grp_last.groups                # KT added to see groups and indexes\n",
    "\n",
    "# Then apply methods to the group in a 2nd step, e.g., .get_group \n",
    "grp_last.get_group('Doe')\n",
    "\n",
    "# Apply a function (.value_counts) to a column after already being grouped\n",
    "# Can filter furtther with .loc makes it loke usiong a filter\n",
    "# Can also get percentage like above with (normalize=True)*100\n",
    "grp_last['first'].value_counts() #.loc['Smith']\n",
    "\n",
    "# Can retrive multiple columns and perform other aggregate functions with their methods \n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].median() #.loc[['Smith' , 'Doe']]\n",
    "\n",
    "# *** Or use more generic form to apply multiple aggregated functions with .agg ***\n",
    "# Seems most generic to me!!!\n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].agg(['count', 'mean', 'std']) #.loc[['Smith' , 'Doe']]\n",
    "\n",
    "# Counting rows with filter.  Counts true's in the returned series with .sum\n",
    "filt = df['last'] == 'Doe'\n",
    "df.loc[filt]['first'].str.contains('Jane').sum()\n",
    "\n",
    "# But for a group need to .apply the function to all the group's series \n",
    "grp_last['first'].apply(lambda x: x.str.contains('n').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Calculating Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the percentage with an n in their first name and group by surname\n",
    "\n",
    "# Create a series of the number of people with each surname\n",
    "surname_count = df['last'].value_counts()\n",
    "surname_count\n",
    "\n",
    "# Create a series of people with each surname, with 'n' in first name\n",
    "surname_count_with_n = grp_last['first'].apply(lambda x: x.str.contains('n').sum())\n",
    "surname_count_with_n\n",
    "\n",
    "# Merge the 2 series togther, add and calculate the percentage (answer column) and tidy up column names\n",
    "df_with_n = pd.concat([surname_count, surname_count_with_n], axis='columns', sort=False)\n",
    "df_with_n['percentage'] = df_with_n['first']/df_with_n['last']*100\n",
    "df_with_n.rename(columns={'first': 'First_with_an_n', 'last': 'Surname'}, inplace=True)\n",
    "df_with_n.sort_values('percentage', ascending=False)\n",
    "# df_with_n.loc['Smith']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Checking for Dirty Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Nulls\n",
    "# dirty_df.isna().sum()                             # Identify na values (by getting a mask) rather than drop them with .isna\n",
    "# # or\n",
    "# dirty_df.isna()\n",
    "\n",
    "# Checking for wrong Types\n",
    "dirty_df.dtypes                                    # Identify if data type is correct. \n",
    "                                                    # If numeric are wrong many aggrate functions won't work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Dropping Dirty Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty_df.dropna()                                 # Drop any / all _rows_ that aren't totally complete with .dropna & how = 'any'\n",
    "                                                    # default values are: dirty_df.dropna(axis='index', how='any')\n",
    "\n",
    "# dirty_df.dropna(                                  # Drop rows that have missing data in 'any' specified rows with subset=[]\n",
    "    # axis='index', how='any', \n",
    "    # subset=['last', 'email'])\n",
    "\n",
    "# dirty_df.dropna(axis='columns')                   # Drop incomplete _columns_.  Which is all of them due to row 4\n",
    "\n",
    "# dirty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Replacing Dirty Data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1 Replacing Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Nulls\n",
    "dirty_df.replace('NA', np.nan, inplace=True)          # Replace unusual 'nill' values (in these cases 'NA' & 'Missing') \n",
    "dirty_df.replace('Missing', np.nan, inplace=True)     # with the proper np.nan value across whole data frame\n",
    "# Could do all this at import time for csv pd.read_csv(XXXXX..., na_values=['NA','None'])\n",
    "\n",
    "dirty_df.fillna(0)                                    # Replaces np.nan  values with an actual value. Most usful for NUMERIC data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.2 Replacing Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Bad Types\n",
    "# dirty_df['age'] = df['age'].astype(float)             # Casting a column to the correct data type with .astype\n",
    "                                                        # Can use .astype on whole dataframe too.\n",
    "                                                        # Use float not int, as NaN is a float.\n",
    "# More elegant way to change multiple types:\n",
    "# !!!!! Needs example updating as data values don't marry up !!!!!\n",
    "# df = df.assign(\n",
    "#     date=       lambda x: pd.to_datetime(x['date']),\n",
    "#     volume =    lambda x: x['volume'].astype(int)\n",
    "#     )\n",
    "                                                        \n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Making a Column Datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_df['Date'] = pd.to_datetime(datetime_df['Date'])\n",
    "# datetime_df.set_index(['Date'], inplace=True)\n",
    "# datetime_df.dtypes\n",
    "# datetime_df\n",
    "\n",
    "\n",
    "datetime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df['Date'] = \\\n",
    "    pd.to_datetime(datetime_df['Date'])     # Apply the pandas to_datetime function to a column             \n",
    "\n",
    "# datetime_df['Date'] = \\\n",
    "#     datetime_df['Date'].apply(pd.to_datetime)# Same as above\n",
    "\n",
    "# Can do at import time if prefered\n",
    "datetime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Using Datetime Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_df.loc[0, 'Date'].day_name()   # To find the day name of a single datetime\n",
    "\n",
    "# datetime_df['DayOfWeek'] =\\\n",
    "#     datetime_df['Date'].dt.day_name()   # New column comtaining day name with .dt.day_name()\n",
    "\n",
    "# Some self explanatory date functions\n",
    "# print(datetime_df['Date'].min())\n",
    "# print(datetime_df['Date'].max())\n",
    "# print(datetime_df['Date'].max() - datetime_df['Date'].min()) # Known as time delta\n",
    "\n",
    "# Filtering on date range in str converted to a datetime with .to_datetime\n",
    "filt = (\n",
    "    datetime_df['Date'] >= pd.to_datetime('2020-03-13 16:00:00')) & (\n",
    "    datetime_df['Date'] < pd.to_datetime('2020-03-13 18:00:00'))\n",
    "\n",
    "datetime_df.loc[filt]\n",
    "# datetime_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Using Datetime as an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df.set_index('Date', inplace=True)       # Setting date column as an index for later functions\n",
    "datetime_df.index\n",
    "\n",
    "datetime_df.loc['2020-03-13 16:00']               # Single value slice on index with .loc\n",
    "\n",
    "# datetime_df.loc[                                  # Slice on index with .loc and for range :\n",
    "#     '2020-03-13 17:00':'2020-03-13 19:00']                    \n",
    "\n",
    "# datetime_df.loc[\n",
    "#     '2020-03-13 17:00':'2020-03-13 19:00'][        # Get an aggregate value of a column sliced by date \n",
    "#     'Close'].mean()    \n",
    "\n",
    "# datetime_df['High'].resample('D').max()         # Resample (downsample) a range using 'D' for day and .resample\n",
    "# datetime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Plots WIP from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df\n",
    "\n",
    "# datetime_df['Date'] = pd.to_datetime(datetime_df['Date'])\n",
    "# datetime_df.set_index(['Date'], inplace=True)\n",
    "# datetime_df.dtypes\n",
    "# datetime_df\n",
    "\n",
    "\n",
    "\n",
    "# Setup Series to Plot\n",
    "highs = datetime_df['High'].resample('H').max()\n",
    "highs\n",
    "\n",
    "# # Quick line plot with mathplot & a Magic command needed for Jupyter notebook\n",
    "# %matplotlib inline \n",
    "# highs.plot()\n",
    "\n",
    "\n",
    "# datetime_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample whole dataframe with single aggregation method\n",
    "df.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample whole dataframe with diferent aggregations with a map & .agg method\n",
    "df.resample('W').agg({'Close': 'mean', 'High': 'max', 'Low': 'min', 'Volume': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesson 10 - Date Time Series\n",
    "# Can use ,format= if .to_datetime doesn't auto recognise the date / time format\n",
    "df = pd.read_csv('time_series.csv')\n",
    "df['Date']=pd.to_datetime(df['Date'], format='%Y-%m-%d %I-%p')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Common Problems  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X.1 \"SettingWithCopyWarning\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"SettingWithCopyWarning\" fixed with .copy() \n",
    "# to explicitly decare that new opbject is a copy not a reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX.  To File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Chap 3 Section 5\n",
    "Cleaning, handling duplicate, missing or invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()           # Will show missing values (nulls) and data types\n",
    "# df.describe()       # This will show some errors up in the dataset, eg unreasonably large or small\n",
    "\n",
    "pd.DataFrame({      # Really nice way to gather summary stats for targeted rows into a data frame\n",
    "    'np.inf Snow Depth': df[df.SNWD == np.inf].SNOW.describe(),\n",
    "    '-np.inf Snow Depth': df[df.SNWD == -np.inf].SNOW.describe()\n",
    "}).T                # Note the .T to transpose the results\n",
    "\n",
    "df.describe(include='object')   # Check the descripbe for datetime and others\n",
    "\n",
    "df[df.duplicated(['date', 'station'])]  # Returns the rows (after the first) that \n",
    "                                        # are duplicated in the columns mentioned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qurying Data\n",
    "snow_data = weather.query('datatype == \"SNOW\" and value > 0 and station.str.contains(\"US1NY\")')\n",
    "snow_data.head()\n",
    "\n",
    "valid_station = dirty_data.query('station != \"?\"').drop(columns=['WESF', 'station'])\n",
    "station_with_wesf = dirty_data.query('station == \"?\"').drop(columns=['station', 'TOBS', 'TMIN', 'TMAX'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Dataframes\n",
    "# By default, `merge()` performs an inner join. We simply specify the columns to use for the join. The left dataframe is the one we call `merge()` on, and the right one is passed in as an argument:\n",
    "\n",
    "# inner_join = weather.merge(station_info, left_on='station', right_on='id')\n",
    "# left_join = station_info.merge(weather, left_on='id', right_on='station', how='left')\n",
    "# right_join = weather.merge(station_info, left_on='station', right_on='id', how='right')\n",
    "\n",
    "# valid_station.merge(\n",
    "#     station_with_wesf, how='left', left_index=True, right_index=True, suffixes=('', '_?')\n",
    "# ).query('WESF > 0').head()\n",
    "\n",
    "\n",
    "# Merge will do everything that .join can do.  .join is a bit easier to use but only works on indexes\n",
    "# valid_station.join(station_with_wesf, how='left', rsuffix='_?').query('WESF > 0').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins can be very resource-intensive, so it's a good idea to figure out what type of join you need using set operations before trying the join itself. \n",
    "# weather.index.intersection(station_info.index)\n",
    "# weather.index.difference(station_info.index)\n",
    "# station_info.index.difference(weather.index)\n",
    "# weather.index.unique().union(station_info.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arithmetic and statistics\n",
    "# We already saw that we can use mathematical operators like `+` and `/` with dataframes directly. However, we can also use methods, which allow us to specify the axis to perform the calculation over. By default, this is per column. Let's find the Z-scores for the volume traded and look at the days where this was more than 3 standard deviations from the mean:\n",
    "\n",
    "# .sub\n",
    "# .mean()\n",
    "# .div\n",
    "# .std()\n",
    "# .abs()\n",
    "# .rank()\n",
    "# .pct_change()\n",
    "# .any()\n",
    "# .all()\n",
    "\n",
    "\n",
    "# pd.cut() to create bins of even range in volume\n",
    "\n",
    "# pd.qcut() to create bins of even content counts\n",
    "# \n",
    "\n",
    "# ## Applying Functions\n",
    "# We can use the `apply()` method to run the same operation \n",
    "# oct_weather_z_scores = central_park_weather\\\n",
    "#     .loc['2018-10', ['TMIN', 'TMAX', 'PRCP']]\\\n",
    "#     .apply(lambda x: x.sub(x.mean()).div(x.std()))\n",
    "# oct_weather_z_scores.describe().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use merge, which is an inner join by default:\n",
    "\n",
    "pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "Or join, which is a left join by default:\n",
    "\n",
    "df1.join(df2)\n",
    "Or concat), which is an outer join by default:\n",
    "\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b9aa4b47fde6b9659f2be704d3beb3fd8a605c3f7f9db8b3f63f09d360b7471"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('conda_3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
