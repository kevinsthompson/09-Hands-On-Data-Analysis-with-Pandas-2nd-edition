{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kevin's Pandas' Crib Sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whays to get help:\n",
    "\n",
    "| Command           | Function |\n",
    "|---------------    |----------|\n",
    "| Auto complete     | To get options |\n",
    "| Hover             |     To get docstring |\n",
    "| `dir(func)`       | Shows all method and function calls |\n",
    "| `help(func)`      | See documentation |\n",
    "| ?                 | Access documentation |\n",
    "| ??                | Access source code |\n",
    "| %lsmagic          | List available magic commands |\n",
    "| %quickref         | Magic quick refernce sheet |\n",
    "\n",
    "Good guide [here](https://problemsolvingwithpython.com/02-Jupyter-Notebooks/02.07-Getting-Help-in-a-Jupyter-Notebook/)\n",
    "\n",
    "Good tips, but focused on Jupyter Notebook in browser [here](https://towardsdatascience.com/15-tips-and-tricks-for-jupyter-notebook-that-will-ease-your-coding-experience-e469207ac95c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a consolidation of notes and examples from:\n",
    "> Coreys MSchafer's Pandas videos [here](https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS) \n",
    "\n",
    "and \n",
    "\n",
    "> Hands on Data Analysis by Stefanie Molin\n",
    "All data in examples and exercises available [here](https://github.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition)\n",
    "\n",
    "Version 2.1W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set-Up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Main Dataset Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Functions that create example datasets for use later \n",
    "\n",
    "def mk_dictionary(x):\n",
    "    if x == \"people\":\n",
    "        dictionary = {\n",
    "            'first': ['Corey', 'Jane', 'Janey', 'John', 'Jimmy'], \n",
    "            'last': ['Schafer', 'Doe', 'Doe', 'Doe', 'Doe'], \n",
    "            'email': [\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JaneyDoe@email.com','JohnDoe@email.com', 'JimmyDoe@email.com']\n",
    "        }\n",
    "    elif x == 'people2':\n",
    "        dictionary = {\n",
    "            'first': ['Tony', 'Steve'], \n",
    "            'last': ['Stark', 'Rogers'], \n",
    "            'email': ['IronMan@avenge.com', 'Cap@avenge.com']\n",
    "        }\n",
    "    elif x == 'dirty':\n",
    "        dictionary = {\n",
    "    'first': ['Corey', 'Corey', 'Jane', 'John', 'Chris', np.nan, None, 'NA'], \n",
    "    'last': ['Schafer', 'Schafer', 'Doe', 'Doe', 'Schafer', np.nan, np.nan, 'Missing'], \n",
    "    'email': ['CoreyMSchafer@gmail.com','CoreyCORRUPTSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com', None, np.nan, 'Anonymous@email.com', 'NA'],\n",
    "    'age': ['33', '333', '55', '63', '36', None, None, 'Missing']\n",
    "    }\n",
    "    elif x == 'weather':\n",
    "        dictionary = big_dictionary('weather')\n",
    "    elif x == 'stations':\n",
    "        dictionary = {\n",
    "            'id': {0: 'GHCND:US1CTFR0022', 4: 'GHCND:US1NJBG0003', 278: 'GHCND:USW00094789'},\n",
    "            'name': {0: 'STAMFORD 2.6 SSW, CT US', 4: 'TENAFLY 1.3 W, NJ US', 278: 'JFK INTERNATIONAL AIRPORT, NY US'},\n",
    "            'latitude': {0: 41.0641, 4: 40.91467, 278: 40.63915},\n",
    "            'longitude': {0: -73.577, 4: -73.9775, 278: -73.76401},\n",
    "            'elevation': {0: 36.6, 4: 21.6, 278: 3.4}\n",
    "        }\n",
    "    else:\n",
    "        print(f'!!!!! mk_dictionary called wih invalid parameter !!!!')\n",
    "        raise SystemExit\n",
    "    return dictionary \n",
    "\n",
    "def mk_dataframe(x):\n",
    "    df =  pd.DataFrame(mk_dictionary(x))\n",
    "    return df\n",
    "\n",
    "# Needed for later \n",
    "people = mk_dictionary('people')\n",
    "\n",
    "# Some tests \n",
    "# df = mk_dataframe('people')\n",
    "# df = mk_dataframe('stations')\n",
    "# df2 = mk_dataframe('people2')\n",
    "# dirty_df = mk_dataframe('dirty')\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Long Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3.1 ___DON'T OPEN___ Very Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datatype</th>\n",
       "      <th>station</th>\n",
       "      <th>attributes</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58914</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>,,N,</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59144</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59145</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59155</th>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>,,N,</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59372</th>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65128</th>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65129</th>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65139</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>,,N,</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65350</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65351</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date datatype            station attributes  value\n",
       "58914  2018-10-01     SNOW  GHCND:US1NJBG0003       ,,N,    0.0\n",
       "59144  2018-10-01     SNOW  GHCND:USW00094789       ,,W,  100.0\n",
       "59145  2018-10-01     SNWD  GHCND:USW00094789   ,,W,2400    0.0\n",
       "59155  2018-10-02     SNOW  GHCND:US1NJBG0003       ,,N,    0.0\n",
       "59372  2018-10-02     SNOW  GHCND:USW00094789       ,,W,    0.0\n",
       "...           ...      ...                ...        ...    ...\n",
       "65128  2018-10-30     SNOW  GHCND:USW00094789       ,,W,    0.0\n",
       "65129  2018-10-30     SNWD  GHCND:USW00094789   ,,W,2400    0.0\n",
       "65139  2018-10-31     SNOW  GHCND:US1NJBG0003       ,,N,    0.0\n",
       "65350  2018-10-31     SNOW  GHCND:USW00094789       ,,W,    0.0\n",
       "65351  2018-10-31     SNWD  GHCND:USW00094789   ,,W,2400    0.0\n",
       "\n",
       "[79 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def big_dictionary(x):\n",
    "    if x == 'weather':\n",
    "        return {    \n",
    "  'date': {58914: '2018-10-01',\n",
    "  59144: '2018-10-01',\n",
    "  59145: '2018-10-01',\n",
    "  59155: '2018-10-02',\n",
    "  59372: '2018-10-02',\n",
    "  59373: '2018-10-02',\n",
    "  59580: '2018-10-03',\n",
    "  59581: '2018-10-03',\n",
    "  59592: '2018-10-04',\n",
    "  59802: '2018-10-04',\n",
    "  59803: '2018-10-04',\n",
    "  59996: '2018-10-05',\n",
    "  59997: '2018-10-05',\n",
    "  60007: '2018-10-06',\n",
    "  60206: '2018-10-06',\n",
    "  60207: '2018-10-06',\n",
    "  60405: '2018-10-07',\n",
    "  60406: '2018-10-07',\n",
    "  60416: '2018-10-08',\n",
    "  60605: '2018-10-08',\n",
    "  60606: '2018-10-08',\n",
    "  60808: '2018-10-09',\n",
    "  60809: '2018-10-09',\n",
    "  60819: '2018-10-10',\n",
    "  61011: '2018-10-10',\n",
    "  61012: '2018-10-10',\n",
    "  61024: '2018-10-11',\n",
    "  61238: '2018-10-11',\n",
    "  61239: '2018-10-11',\n",
    "  61451: '2018-10-12',\n",
    "  61452: '2018-10-12',\n",
    "  61632: '2018-10-13',\n",
    "  61633: '2018-10-13',\n",
    "  61822: '2018-10-14',\n",
    "  61823: '2018-10-14',\n",
    "  62022: '2018-10-15',\n",
    "  62023: '2018-10-15',\n",
    "  62214: '2018-10-16',\n",
    "  62215: '2018-10-16',\n",
    "  62226: '2018-10-17',\n",
    "  62423: '2018-10-17',\n",
    "  62424: '2018-10-17',\n",
    "  62434: '2018-10-18',\n",
    "  62626: '2018-10-18',\n",
    "  62627: '2018-10-18',\n",
    "  62637: '2018-10-19',\n",
    "  62848: '2018-10-19',\n",
    "  62849: '2018-10-19',\n",
    "  63031: '2018-10-20',\n",
    "  63032: '2018-10-20',\n",
    "  63221: '2018-10-21',\n",
    "  63222: '2018-10-21',\n",
    "  63233: '2018-10-22',\n",
    "  63440: '2018-10-22',\n",
    "  63441: '2018-10-22',\n",
    "  63451: '2018-10-23',\n",
    "  63665: '2018-10-23',\n",
    "  63666: '2018-10-23',\n",
    "  63676: '2018-10-24',\n",
    "  63871: '2018-10-24',\n",
    "  63872: '2018-10-24',\n",
    "  63882: '2018-10-25',\n",
    "  64092: '2018-10-25',\n",
    "  64093: '2018-10-25',\n",
    "  64103: '2018-10-26',\n",
    "  64319: '2018-10-26',\n",
    "  64320: '2018-10-26',\n",
    "  64514: '2018-10-27',\n",
    "  64515: '2018-10-27',\n",
    "  64715: '2018-10-28',\n",
    "  64716: '2018-10-28',\n",
    "  64923: '2018-10-29',\n",
    "  64924: '2018-10-29',\n",
    "  64934: '2018-10-30',\n",
    "  65128: '2018-10-30',\n",
    "  65129: '2018-10-30',\n",
    "  65139: '2018-10-31',\n",
    "  65350: '2018-10-31',\n",
    "  65351: '2018-10-31'},\n",
    " 'datatype': {58914: 'SNOW',\n",
    "  59144: 'SNOW',\n",
    "  59145: 'SNWD',\n",
    "  59155: 'SNOW',\n",
    "  59372: 'SNOW',\n",
    "  59373: 'SNWD',\n",
    "  59580: 'SNOW',\n",
    "  59581: 'SNWD',\n",
    "  59592: 'SNOW',\n",
    "  59802: 'SNOW',\n",
    "  59803: 'SNWD',\n",
    "  59996: 'SNOW',\n",
    "  59997: 'SNWD',\n",
    "  60007: 'SNOW',\n",
    "  60206: 'SNOW',\n",
    "  60207: 'SNWD',\n",
    "  60405: 'SNOW',\n",
    "  60406: 'SNWD',\n",
    "  60416: 'SNOW',\n",
    "  60605: 'SNOW',\n",
    "  60606: 'SNWD',\n",
    "  60808: 'SNOW',\n",
    "  60809: 'SNWD',\n",
    "  60819: 'SNOW',\n",
    "  61011: 'SNOW',\n",
    "  61012: 'SNWD',\n",
    "  61024: 'SNOW',\n",
    "  61238: 'SNOW',\n",
    "  61239: 'SNWD',\n",
    "  61451: 'SNOW',\n",
    "  61452: 'SNWD',\n",
    "  61632: 'SNOW',\n",
    "  61633: 'SNWD',\n",
    "  61822: 'SNOW',\n",
    "  61823: 'SNWD',\n",
    "  62022: 'SNOW',\n",
    "  62023: 'SNWD',\n",
    "  62214: 'SNOW',\n",
    "  62215: 'SNWD',\n",
    "  62226: 'SNOW',\n",
    "  62423: 'SNOW',\n",
    "  62424: 'SNWD',\n",
    "  62434: 'SNOW',\n",
    "  62626: 'SNOW',\n",
    "  62627: 'SNWD',\n",
    "  62637: 'SNOW',\n",
    "  62848: 'SNOW',\n",
    "  62849: 'SNWD',\n",
    "  63031: 'SNOW',\n",
    "  63032: 'SNWD',\n",
    "  63221: 'SNOW',\n",
    "  63222: 'SNWD',\n",
    "  63233: 'SNOW',\n",
    "  63440: 'SNOW',\n",
    "  63441: 'SNWD',\n",
    "  63451: 'SNOW',\n",
    "  63665: 'SNOW',\n",
    "  63666: 'SNWD',\n",
    "  63676: 'SNOW',\n",
    "  63871: 'SNOW',\n",
    "  63872: 'SNWD',\n",
    "  63882: 'SNOW',\n",
    "  64092: 'SNOW',\n",
    "  64093: 'SNWD',\n",
    "  64103: 'SNOW',\n",
    "  64319: 'SNOW',\n",
    "  64320: 'SNWD',\n",
    "  64514: 'SNOW',\n",
    "  64515: 'SNWD',\n",
    "  64715: 'SNOW',\n",
    "  64716: 'SNWD',\n",
    "  64923: 'SNOW',\n",
    "  64924: 'SNWD',\n",
    "  64934: 'SNOW',\n",
    "  65128: 'SNOW',\n",
    "  65129: 'SNWD',\n",
    "  65139: 'SNOW',\n",
    "  65350: 'SNOW',\n",
    "  65351: 'SNWD'},\n",
    " 'station': {58914: 'GHCND:US1NJBG0003',\n",
    "  59144: 'GHCND:USW00094789',\n",
    "  59145: 'GHCND:USW00094789',\n",
    "  59155: 'GHCND:US1NJBG0003',\n",
    "  59372: 'GHCND:USW00094789',\n",
    "  59373: 'GHCND:USW00094789',\n",
    "  59580: 'GHCND:USW00094789',\n",
    "  59581: 'GHCND:USW00094789',\n",
    "  59592: 'GHCND:US1NJBG0003',\n",
    "  59802: 'GHCND:USW00094789',\n",
    "  59803: 'GHCND:USW00094789',\n",
    "  59996: 'GHCND:USW00094789',\n",
    "  59997: 'GHCND:USW00094789',\n",
    "  60007: 'GHCND:US1NJBG0003',\n",
    "  60206: 'GHCND:USW00094789',\n",
    "  60207: 'GHCND:USW00094789',\n",
    "  60405: 'GHCND:USW00094789',\n",
    "  60406: 'GHCND:USW00094789',\n",
    "  60416: 'GHCND:US1NJBG0003',\n",
    "  60605: 'GHCND:USW00094789',\n",
    "  60606: 'GHCND:USW00094789',\n",
    "  60808: 'GHCND:USW00094789',\n",
    "  60809: 'GHCND:USW00094789',\n",
    "  60819: 'GHCND:US1NJBG0003',\n",
    "  61011: 'GHCND:USW00094789',\n",
    "  61012: 'GHCND:USW00094789',\n",
    "  61024: 'GHCND:US1NJBG0003',\n",
    "  61238: 'GHCND:USW00094789',\n",
    "  61239: 'GHCND:USW00094789',\n",
    "  61451: 'GHCND:USW00094789',\n",
    "  61452: 'GHCND:USW00094789',\n",
    "  61632: 'GHCND:USW00094789',\n",
    "  61633: 'GHCND:USW00094789',\n",
    "  61822: 'GHCND:USW00094789',\n",
    "  61823: 'GHCND:USW00094789',\n",
    "  62022: 'GHCND:USW00094789',\n",
    "  62023: 'GHCND:USW00094789',\n",
    "  62214: 'GHCND:USW00094789',\n",
    "  62215: 'GHCND:USW00094789',\n",
    "  62226: 'GHCND:US1NJBG0003',\n",
    "  62423: 'GHCND:USW00094789',\n",
    "  62424: 'GHCND:USW00094789',\n",
    "  62434: 'GHCND:US1NJBG0003',\n",
    "  62626: 'GHCND:USW00094789',\n",
    "  62627: 'GHCND:USW00094789',\n",
    "  62637: 'GHCND:US1NJBG0003',\n",
    "  62848: 'GHCND:USW00094789',\n",
    "  62849: 'GHCND:USW00094789',\n",
    "  63031: 'GHCND:USW00094789',\n",
    "  63032: 'GHCND:USW00094789',\n",
    "  63221: 'GHCND:USW00094789',\n",
    "  63222: 'GHCND:USW00094789',\n",
    "  63233: 'GHCND:US1NJBG0003',\n",
    "  63440: 'GHCND:USW00094789',\n",
    "  63441: 'GHCND:USW00094789',\n",
    "  63451: 'GHCND:US1NJBG0003',\n",
    "  63665: 'GHCND:USW00094789',\n",
    "  63666: 'GHCND:USW00094789',\n",
    "  63676: 'GHCND:US1NJBG0003',\n",
    "  63871: 'GHCND:USW00094789',\n",
    "  63872: 'GHCND:USW00094789',\n",
    "  63882: 'GHCND:US1NJBG0003',\n",
    "  64092: 'GHCND:USW00094789',\n",
    "  64093: 'GHCND:USW00094789',\n",
    "  64103: 'GHCND:US1NJBG0003',\n",
    "  64319: 'GHCND:USW00094789',\n",
    "  64320: 'GHCND:USW00094789',\n",
    "  64514: 'GHCND:USW00094789',\n",
    "  64515: 'GHCND:USW00094789',\n",
    "  64715: 'GHCND:USW00094789',\n",
    "  64716: 'GHCND:USW00094789',\n",
    "  64923: 'GHCND:USW00094789',\n",
    "  64924: 'GHCND:USW00094789',\n",
    "  64934: 'GHCND:US1NJBG0003',\n",
    "  65128: 'GHCND:USW00094789',\n",
    "  65129: 'GHCND:USW00094789',\n",
    "  65139: 'GHCND:US1NJBG0003',\n",
    "  65350: 'GHCND:USW00094789',\n",
    "  65351: 'GHCND:USW00094789'},\n",
    " 'attributes': {58914: ',,N,',\n",
    "  59144: ',,W,',\n",
    "  59145: ',,W,2400',\n",
    "  59155: ',,N,',\n",
    "  59372: ',,W,',\n",
    "  59373: ',,W,2400',\n",
    "  59580: ',,W,',\n",
    "  59581: ',,W,2400',\n",
    "  59592: ',,N,',\n",
    "  59802: ',,W,',\n",
    "  59803: ',,W,2400',\n",
    "  59996: ',,W,',\n",
    "  59997: ',,W,2400',\n",
    "  60007: ',,N,',\n",
    "  60206: ',,W,',\n",
    "  60207: ',,W,2400',\n",
    "  60405: ',,W,',\n",
    "  60406: ',,W,2400',\n",
    "  60416: ',,N,',\n",
    "  60605: ',,W,',\n",
    "  60606: ',,W,2400',\n",
    "  60808: ',,W,',\n",
    "  60809: ',,W,2400',\n",
    "  60819: ',,N,',\n",
    "  61011: ',,W,',\n",
    "  61012: ',,W,2400',\n",
    "  61024: ',,N,',\n",
    "  61238: ',,W,',\n",
    "  61239: ',,W,2400',\n",
    "  61451: ',,W,',\n",
    "  61452: ',,W,2400',\n",
    "  61632: ',,W,',\n",
    "  61633: ',,W,2400',\n",
    "  61822: ',,W,',\n",
    "  61823: ',,W,2400',\n",
    "  62022: ',,W,',\n",
    "  62023: ',,W,2400',\n",
    "  62214: ',,W,',\n",
    "  62215: ',,W,2400',\n",
    "  62226: ',,N,',\n",
    "  62423: ',,W,',\n",
    "  62424: ',,W,2400',\n",
    "  62434: ',,N,',\n",
    "  62626: ',,W,',\n",
    "  62627: ',,W,2400',\n",
    "  62637: ',,N,',\n",
    "  62848: ',,W,',\n",
    "  62849: ',,W,2400',\n",
    "  63031: ',,W,',\n",
    "  63032: ',,W,2400',\n",
    "  63221: ',,W,',\n",
    "  63222: ',,W,2400',\n",
    "  63233: ',,N,',\n",
    "  63440: ',,W,',\n",
    "  63441: ',,W,2400',\n",
    "  63451: ',,N,',\n",
    "  63665: ',,W,',\n",
    "  63666: ',,W,2400',\n",
    "  63676: ',,N,',\n",
    "  63871: ',,W,',\n",
    "  63872: ',,W,2400',\n",
    "  63882: ',,N,',\n",
    "  64092: ',,W,',\n",
    "  64093: ',,W,2400',\n",
    "  64103: ',,N,',\n",
    "  64319: ',,W,',\n",
    "  64320: ',,W,2400',\n",
    "  64514: ',,W,',\n",
    "  64515: ',,W,2400',\n",
    "  64715: ',,W,',\n",
    "  64716: ',,W,2400',\n",
    "  64923: ',,W,',\n",
    "  64924: ',,W,2400',\n",
    "  64934: ',,N,',\n",
    "  65128: ',,W,',\n",
    "  65129: ',,W,2400',\n",
    "  65139: ',,N,',\n",
    "  65350: ',,W,',\n",
    "  65351: ',,W,2400'},\n",
    " 'value': {58914: 0.0,\n",
    "  59144: 100.0,\n",
    "  59145: 0.0,\n",
    "  59155: 0.0,\n",
    "  59372: 0.0,\n",
    "  59373: 0.0,\n",
    "  59580: 0.0,\n",
    "  59581: 0.0,\n",
    "  59592: 0.0,\n",
    "  59802: 0.0,\n",
    "  59803: 0.0,\n",
    "  59996: 0.0,\n",
    "  59997: 0.0,\n",
    "  60007: 0.0,\n",
    "  60206: 0.0,\n",
    "  60207: 0.0,\n",
    "  60405: 0.0,\n",
    "  60406: 0.0,\n",
    "  60416: 0.0,\n",
    "  60605: 0.0,\n",
    "  60606: 0.0,\n",
    "  60808: 0.0,\n",
    "  60809: 0.0,\n",
    "  60819: 0.0,\n",
    "  61011: 0.0,\n",
    "  61012: 0.0,\n",
    "  61024: 0.0,\n",
    "  61238: 0.0,\n",
    "  61239: 0.0,\n",
    "  61451: 0.0,\n",
    "  61452: 0.0,\n",
    "  61632: 0.0,\n",
    "  61633: 0.0,\n",
    "  61822: 0.0,\n",
    "  61823: 0.0,\n",
    "  62022: 0.0,\n",
    "  62023: 0.0,\n",
    "  62214: 0.0,\n",
    "  62215: 0.0,\n",
    "  62226: 0.0,\n",
    "  62423: 0.0,\n",
    "  62424: 0.0,\n",
    "  62434: 0.0,\n",
    "  62626: 0.0,\n",
    "  62627: 0.0,\n",
    "  62637: 0.0,\n",
    "  62848: 0.0,\n",
    "  62849: 0.0,\n",
    "  63031: 0.0,\n",
    "  63032: 0.0,\n",
    "  63221: 0.0,\n",
    "  63222: 0.0,\n",
    "  63233: 0.0,\n",
    "  63440: 0.0,\n",
    "  63441: 0.0,\n",
    "  63451: 0.0,\n",
    "  63665: 0.0,\n",
    "  63666: 0.0,\n",
    "  63676: 0.0,\n",
    "  63871: 0.0,\n",
    "  63872: 0.0,\n",
    "  63882: 0.0,\n",
    "  64092: 0.0,\n",
    "  64093: 0.0,\n",
    "  64103: 0.0,\n",
    "  64319: 0.0,\n",
    "  64320: 0.0,\n",
    "  64514: 0.0,\n",
    "  64515: 0.0,\n",
    "  64715: 0.0,\n",
    "  64716: 0.0,\n",
    "  64923: 0.0,\n",
    "  64924: 0.0,\n",
    "  64934: 0.0,\n",
    "  65128: 0.0,\n",
    "  65129: 0.0,\n",
    "  65139: 0.0,\n",
    "  65350: 0.0,\n",
    "  65351: 0.0}\n",
    " }\n",
    "                \n",
    "df = mk_dataframe('weather')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 DateTime \n",
    "___XXX Need to Refeactor This To Use Normal Dataframe Constructior but this as Dictionary Contrustor XXX___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_datetime_dataframe():\n",
    "  datetime_df = pd.DataFrame(\n",
    "    {'Date': {0: ('2020-03-13 20:00:00'),\n",
    "      1: ('2020-03-13 19:00:00'),\n",
    "      2: ('2020-03-13 18:00:00'),\n",
    "      3: ('2020-03-13 17:00:00'),\n",
    "      4: ('2020-03-13 16:00:00'),\n",
    "      5: ('2020-03-13 15:00:00')},\n",
    "    'Symbol': {0: 'ETHUSD',\n",
    "      1: 'ETHUSD',\n",
    "      2: 'ETHUSD',\n",
    "      3: 'ETHUSD',\n",
    "      4: 'ETHUSD',\n",
    "      5: 'ETHUSD'},\n",
    "    'Open': {0: 129.94, 1: 119.51, 2: 124.47, 3: 124.08, 4: 124.85, 5: 128.39},\n",
    "    'High': {0: 131.82, 1: 132.02, 2: 124.85, 3: 127.42, 4: 129.51, 5: 128.9},\n",
    "    'Low': {0: 126.87, 1: 117.1, 2: 115.5, 3: 121.63, 4: 120.17, 5: 116.06},\n",
    "    'Close': {0: 128.71, 1: 129.94, 2: 119.51, 3: 124.47, 4: 124.08, 5: 124.85},\n",
    "    'Volume': {0: 1940673.93,\n",
    "      1: 7579741.09,\n",
    "      2: 4898735.81,\n",
    "      3: 2753450.92,\n",
    "      4: 4461424.71,\n",
    "      5: 7378976.0}}\n",
    "  )\n",
    "  datetime_df['Date'] = pd.to_datetime(datetime_df['Date'])\n",
    "  datetime_df.set_index('Date', inplace=True)       # Setting date column as an index for later functions\n",
    "  datetime_df.index\n",
    "  return datetime_df\n",
    "\n",
    "datetime_df = mk_datetime_dataframe()\n",
    "# datetime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Making a Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                    email  first     last  \\\n",
       "0  Corey  Schafer  CoreyMSchafer@gmail.com  Corey  Schafer   \n",
       "1   Jane      Doe        JaneDoe@email.com   Jane      Doe   \n",
       "2  Janey      Doe       JaneyDoe@email.com  Janey      Doe   \n",
       "3   John      Doe        JohnDoe@email.com   John      Doe   \n",
       "4  Jimmy      Doe       JimmyDoe@email.com  Jimmy      Doe   \n",
       "\n",
       "                     email  \n",
       "0  CoreyMSchafer@gmail.com  \n",
       "1        JaneDoe@email.com  \n",
       "2       JaneyDoe@email.com  \n",
       "3        JohnDoe@email.com  \n",
       "4       JimmyDoe@email.com  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.DataFrame(people)                  # Making a dataframe from a dictionary\n",
    "df2 = df.copy()                             # copying a whole dataframe.  \n",
    "                                            # .copy() ensures a seperate copy not a link\n",
    "\n",
    "# Example of loading in a  csv in here? \n",
    "\n",
    "# Add a whole new dataframe as new rows\n",
    "pd.concat([df, df2], axis=1)      # Merges the 2 dataframes alomng the column (#1) axis \n",
    "\n",
    "# Load one in from csv and parse dates at load time\n",
    "# weather = pd.read_csv('data/nyc_weather_2018.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick Overview of the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.DataFrame(people)\n",
    "# Quick Overview of Dataframe\n",
    "# Methods\n",
    "# df.info()             # Overview of the dataframe\n",
    "# df.describe()         # Quick summary of the frame, best for wide format\n",
    "# df.head(10)           # List top x rows (default is 5)\n",
    "# df.tail()             # List bottom x rows (default is 5)\n",
    "# df.sample()           # List randon x rows (default is 1)\n",
    "\n",
    "# Properties \n",
    "# df.columns            # List column names\n",
    "# df.shape              # Count of rows, count of columns\n",
    "# df.dtypes\n",
    "\n",
    "# Quick Oevrview of a Column\n",
    "# df['last'].describe()         # Quick summary of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         first     last\n",
      "email                                  \n",
      "CoreyMSchafer@gmail.com  Corey  Schafer\n",
      "JaneDoe@email.com         Jane      Doe\n",
      "JaneyDoe@email.com       Janey      Doe\n",
      "JohnDoe@email.com         John      Doe\n",
      "JimmyDoe@email.com       Jimmy      Doe\n"
     ]
    }
   ],
   "source": [
    "df = mk_dataframe('people')\n",
    "# Set a new index. Keep it set with `inplace``.  \n",
    "# Indexes don't have to be unique\n",
    "df.set_index('email', inplace=True)     # Set a column to be an index\n",
    "# print(df.index)\n",
    "print(df)\n",
    "\n",
    "# df.reset_index(inplace=True)            # Reset row number to indexes \n",
    "                                          # Good to 'save'a column currently used a an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accessing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Access Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                    email\n",
       "0  Corey  Schafer  CoreyMSchafer@gmail.com\n",
       "1   Jane      Doe        JaneDoe@email.com\n",
       "2  Janey      Doe       JaneyDoe@email.com\n",
       "3   John      Doe        JohnDoe@email.com\n",
       "4  Jimmy      Doe       JimmyDoe@email.com"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mk_dataframe('people')\n",
    "df                                # Simple access to all \n",
    "# df['email']                       # Access single column\n",
    "# df[['last', 'email']]             # Access multiple columns by using a list (a list within the list)i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Access Values `.loc` and `.iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mk_dataframe('people')             #Setup\n",
    "df.set_index('email', inplace=True)     #Setup\n",
    "\n",
    "# df.iloc[[0, 1, 3],[1,0]]              # Access by integer reference / index by using .iloc.  \n",
    "                                        # .loc and iloc takes row index first\n",
    "\n",
    "# df.loc[                               # Access by row index name .loc\n",
    "#     'CoreyMSchafer@gmail.com', ['first', 'last']]   \n",
    "\n",
    "# df.loc[                               # As above plus multi selected rows and columns \n",
    "#     ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com'], \n",
    "#     ['first', 'last']]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best to filter with 2 part process:\n",
    "\n",
    "\n",
    "1. Set filter \n",
    "2. Apply filter\n",
    "\n",
    "_Can't use word 'filter' as a variable name it's reserved.  'rows' works well_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email\n",
       "CoreyMSchafer@gmail.com    Schafer\n",
       "JohnDoe@email.com              Doe\n",
       "Name: last, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mk_dataframe('people')             #Setup\n",
    "df.set_index('email', inplace=True)     #Setup\n",
    "\n",
    "rows = (\n",
    "    df['last'] == 'Schafer') |(         # 1) Set filter.  An exampe of an 'or' '|' filter\n",
    "    df['first'] == 'John')              # Note the line breaks\n",
    "df.loc[rows, 'last']                    # 2) Apply filter or\n",
    "# df.loc[~rows, 'last']                 # 2) Apply inverse of filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Querying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datatype</th>\n",
       "      <th>station</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59145</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59373</th>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59581</th>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59803</th>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date datatype            station  value\n",
       "59145  2018-10-01     SNWD  GHCND:USW00094789    0.0\n",
       "59373  2018-10-02     SNWD  GHCND:USW00094789    0.0\n",
       "59581  2018-10-03     SNWD  GHCND:USW00094789    0.0\n",
       "59803  2018-10-04     SNWD  GHCND:USW00094789    0.0\n",
       "59997  2018-10-05     SNWD  GHCND:USW00094789    0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = mk_dataframe('weather')\n",
    "dirty = mk_dataframe('dirty')\n",
    "\n",
    "snow_data = weather.query(\n",
    "    'datatype == \"SNOW\" and station.str.contains(\"US1NJ\")'\n",
    "    )\n",
    "\n",
    "snow_data = weather.query(\n",
    "    'datatype != \"SNOW\"'\n",
    "    ).drop(columns=['attributes'])\n",
    "\n",
    "snow_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Checking for Dirty Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mk_dataframe('dirty')\n",
    "# Checking for Nulls\n",
    "# df.info()                 # Will show missing values (nulls) and data types\n",
    "# df.isna().sum()           # Identify na values (by getting a mask) rather than drop them with .isna\n",
    "# # or\n",
    "# dirty_df.isna()\n",
    "\n",
    "# Checking for wrong Types\n",
    "# df.dtypes                 # Identify if data type is correct. \n",
    "                            # If numeric are wrong many aggrate functions won't work \n",
    "\n",
    "# df.describe()             # This will show some errors up in the dataset, \n",
    "                            # eg unreasonably large or small\n",
    "\n",
    "# df.describe(              # Check the describe for datetime and others\n",
    "#     include='object')  \n",
    "\n",
    "# df[df.duplicated(          # Returns the rows (after the first) that\n",
    "#     ['first', 'last'])]    # are duplicated in the columns mentioned   \n",
    "                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Dropping Dirty Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyCORRUPTSchafer@gmail.com</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NA</td>\n",
       "      <td>Missing</td>\n",
       "      <td>NA</td>\n",
       "      <td>Missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                          email      age\n",
       "0  Corey  Schafer        CoreyMSchafer@gmail.com       33\n",
       "1  Corey  Schafer  CoreyCORRUPTSchafer@gmail.com      333\n",
       "2   Jane      Doe              JaneDoe@email.com       55\n",
       "3   John      Doe              JohnDoe@email.com       63\n",
       "7     NA  Missing                             NA  Missing"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mk_dataframe('dirty')\n",
    "\n",
    "df.dropna()                             # Drop any / all _rows_ that aren't totally complete with .dropna & how = 'any'\n",
    "                                        # default values are: dirty_df.dropna(axis='index', how='any')\n",
    "\n",
    "# dirty_df.dropna(                      # Drop rows that have missing data in 'any' specified rows with subset=[]\n",
    "    # axis='index', how='any', \n",
    "    # subset=['last', 'email'])\n",
    "\n",
    "# dirty_df.dropna(axis='columns')       # Drop incomplete _columns_.  Which is all of them due to row 4\n",
    "\n",
    "# dirty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Replacing Dirty Data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Replacing Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyCORRUPTSchafer@gmail.com</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anonymous@email.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                          email  age\n",
       "0  Corey  Schafer        CoreyMSchafer@gmail.com   33\n",
       "1  Corey  Schafer  CoreyCORRUPTSchafer@gmail.com  333\n",
       "2   Jane      Doe              JaneDoe@email.com   55\n",
       "3   John      Doe              JohnDoe@email.com   63\n",
       "4  Chris  Schafer                              0   36\n",
       "5      0        0                              0    0\n",
       "6      0        0            Anonymous@email.com    0\n",
       "7      0        0                              0    0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df = mk_dataframe('dirty')\n",
    "\n",
    "dirty_df.replace('NA', np.nan, inplace=True)          # Replace unusual 'nill' values (in these cases 'NA' & 'Missing') \n",
    "dirty_df.replace('Missing', np.nan, inplace=True)     # with the proper np.nan value across whole data frame\n",
    "# Could do all this at import time for csv pd.read_csv(XXXXX..., na_values=['NA','None'])\n",
    "\n",
    "dirty_df.fillna(0)                                    # Replaces np.nan  values with an actual value. Most usful for NUMERIC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Replacing Bad Types   XXX WIP 7/6/22 XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyCORRUPTSchafer@gmail.com</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>None</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anonymous@email.com</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                          email   age\n",
       "0  Corey  Schafer        CoreyMSchafer@gmail.com    33\n",
       "1  Corey  Schafer  CoreyCORRUPTSchafer@gmail.com   333\n",
       "2   Jane      Doe              JaneDoe@email.com    55\n",
       "3   John      Doe              JohnDoe@email.com    63\n",
       "4  Chris  Schafer                           None    36\n",
       "5    NaN      NaN                            NaN  None\n",
       "6   None      NaN            Anonymous@email.com  None"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df = mk_dataframe('dirty').drop([7])\n",
    "# dirty_df['age'] = dirty_df['age'].astype(float)       # Casting a column to the correct data type with .astype\n",
    "                                                        # Can use .astype on whole dataframe too.\n",
    "                                                        # Use float not int, as NaN is a float.\n",
    "\n",
    "# Use Assign to create multiple new columns at once\n",
    "# !!!!! Needs example updating as data values don't marry up !!!!!\n",
    "# df = df.assign(\n",
    "#     date=       lambda x: pd.to_datetime(x['date']),\n",
    "#     volume =    lambda x: x['volume'].astype(int)\n",
    "#     )\n",
    "                                                        \n",
    "dirty_df                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Updating Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Update Column Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                    email\n",
       "0  Corey  Schafer  CoreyMSchafer@gmail.com\n",
       "1   Jane      Doe        JaneDoe@email.com\n",
       "2  Janey      Doe       JaneyDoe@email.com\n",
       "3   John      Doe        JohnDoe@email.com\n",
       "4  Jimmy      Doe       JimmyDoe@email.com"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mk_dataframe('people')             #Setup\n",
    "# df.set_index('email', inplace=True)     #Setup\n",
    "\n",
    "# df.columns = ['email', 'first_name', 'last_name']         # Rename all columns \n",
    "\n",
    "# df.rename(                                                # Rename specific columns using .rename\n",
    "# df.set_index('email', inplace=True)     #Setup\n",
    "#     columns={\n",
    "#         'first_name': 'first', 'last_name': 'last'\n",
    "#         }, inplace=True                                   # Note, need \"inplace\" \n",
    "#     ) \n",
    " \n",
    "# df.columns = [x.upper() for x in df.columns]              # Rename all columns by an inline comprehension .columns\n",
    "\n",
    "# Reset\n",
    "df.columns = [x.lower() for x in df.columns]                # Reset so later examples work\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Update Values - Direct Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>coreymschafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>janedoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Smith</td>\n",
       "      <td>janeysmith@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John2Smith@email.com</td>\n",
       "      <td>John2</td>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>jimmydoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  first     last                    email\n",
       "0                 Corey  Schafer  coreymschafer@gmail.com\n",
       "1                  Jane      Doe        janedoe@email.com\n",
       "2                 Janey    Smith     janeysmith@email.com\n",
       "3  John2Smith@email.com    John2                    Smith\n",
       "4                 Jimmy      Doe       jimmydoe@email.com"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email'] = df['email'].str.lower()                               # Update whole column with string object method with.str.x\n",
    "df.loc[3] = ['John2Smith@email.com', 'John2', 'Smith']              # Update whole row with .loc\n",
    "df.loc[2, ['last', 'email']] = ['Smith', 'janeysmith@email.com']    # Update specific columns of a row with .loc\n",
    "\n",
    "# Update based on filter \n",
    "filt = (df['email'] == 'John2Smith@email.com')                      # Update cells based on a filter with .loc\n",
    "# df[filt]['last'] = 'Smith'                                        # DON'T do this, it won't work\n",
    "df.loc[filt, 'first'] = 'Johnny'                                    # THIS will, need .loc\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Updating Values - with Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four Functions:\n",
    "- `apply`\n",
    "- `applymap` \n",
    "- `map`\n",
    "- `replace`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 `apply` a function to an object (dataframe or series) and get a series as a result\n",
    "- Object can be a series (by default a column) \n",
    "- Object can be a dataframe in which case it's applied to each series (column) for a single result for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first    5\n",
       "last     5\n",
       "email    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying to a column\n",
    "# df['email'].apply(len)            # `apply` the `len` function to the email column\n",
    "\n",
    "# def update_email(email):          # 'apply' your own function\n",
    "#     return email.upper()\n",
    "# df['email'].apply(update_email) \n",
    "\n",
    "# df['email'].apply(                # 'Apply' a your own inline (LAMBDA) function \n",
    "#     lambda x: x.lower()           # to a whole column and get a series as a result\n",
    "#     )  \n",
    "\n",
    "# When applied to a dataframe 'apply' is applied across each series\n",
    "df.apply(len) # or df.apply(len, axis='columns') or df.apply(len, axis='rows')   \n",
    "# df.apply(pd.Series.min)           # Returns the minimum (first in alaphs) in each column\n",
    "\n",
    "# df.apply(                           # Applying a Lambda function to each series\n",
    "#     lambda x: x.min()\n",
    "#     )     \n",
    "\n",
    "\n",
    "# Apply your own function for multiple steps in one go eg:\n",
    "# staff_df['user_name'] = \\\n",
    "#       staff_df['Preferred Name'].apply(clean).str[0] \\\n",
    "#     + staff_df['Family Name'].apply(clean).str[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Applying Functions\n",
    "# We can use the `apply()` method to run the same operation \n",
    "# oct_weather_z_scores = central_park_weather\\\n",
    "#     .loc['2017-10', ['TMIN', 'TMAX', 'PRCP']]\\\n",
    "#     .apply(lambda x: x.sub(x.mean()).div(x.std()))\n",
    "# oct_weather_z_scores.describe().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 `applymap` a function to a dataframe and get a dataframe as a result.  \n",
    "Applied elementwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corey</td>\n",
       "      <td>schafer</td>\n",
       "      <td>coreymschafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jane</td>\n",
       "      <td>doe</td>\n",
       "      <td>janedoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>janey</td>\n",
       "      <td>smith</td>\n",
       "      <td>janeysmith@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>john2smith@email.com</td>\n",
       "      <td>john2</td>\n",
       "      <td>smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jimmy</td>\n",
       "      <td>doe</td>\n",
       "      <td>jimmydoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  first     last                    email\n",
       "0                 corey  schafer  coreymschafer@gmail.com\n",
       "1                  jane      doe        janedoe@email.com\n",
       "2                 janey    smith     janeysmith@email.com\n",
       "3  john2smith@email.com    john2                    smith\n",
       "4                 jimmy      doe       jimmydoe@email.com"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.applymap(len)\n",
    "df.applymap(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 `map` a series and get a series as a result.  \n",
    "Replaces __all__ elements in series  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Chris\n",
       "1     Mary\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "Name: first, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .map only works on a series. Use like a vlookup\n",
    "# Use it to subsitute one value for another via a lookup dictionary.\n",
    "# Unsubtituted vales replaced by NaN\n",
    "df['first'].map({'Corey': 'Chris', 'Jane': 'Mary'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.4 `replace` on an object (series or dataframe) a get same object as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey2</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>coreymschafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane2</td>\n",
       "      <td>Doe</td>\n",
       "      <td>janedoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Smith</td>\n",
       "      <td>janeysmith@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John2Smith@email.com</td>\n",
       "      <td>John2</td>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>jimmydoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  first     last                    email\n",
       "0                Corey2  Schafer  coreymschafer@gmail.com\n",
       "1                 Jane2      Doe        janedoe@email.com\n",
       "2                 Janey    Smith     janeysmith@email.com\n",
       "3  John2Smith@email.com    John2                    Smith\n",
       "4                 Jimmy      Doe       jimmydoe@email.com"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .replace works like map but leaves unsubsittuted values untouched (not NaN)\n",
    "df['first'] = df['first'].replace({'Corey': 'Corey2', 'Jane': 'Jane2'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXXX WIP XXXX\n",
    "# fb.assign(\n",
    "#     abs_z_score_volume=lambda x: \\\n",
    "#         x['volume'].sub(x['volume'].mean()).div(x['volume'].std()).abs()\n",
    "# ).query('abs_z_score_volume > 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Updating Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coreymschafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>janedoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>janeysmith@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jimmydoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     email\n",
       "0  coreymschafer@gmail.com\n",
       "1        janedoe@email.com\n",
       "2     janeysmith@email.com\n",
       "3                    Smith\n",
       "4       jimmydoe@email.com"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove columns with .drop like a db\n",
    "df.drop(columns=['first', 'last'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 Adding Columns Simple and Direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "      <th>full_name</th>\n",
       "      <th>numeric_data_01</th>\n",
       "      <th>numeric_data_02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "      <td>Corey Schafer</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "      <td>Janey Doe</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "      <td>Jimmy Doe</td>\n",
       "      <td>13</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first     last                    email      full_name  numeric_data_01  \\\n",
       "0  Corey  Schafer  CoreyMSchafer@gmail.com  Corey Schafer               78   \n",
       "1   Jane      Doe        JaneDoe@email.com       Jane Doe               32   \n",
       "2  Janey      Doe       JaneyDoe@email.com      Janey Doe               62   \n",
       "3   John      Doe        JohnDoe@email.com       John Doe               43   \n",
       "4  Jimmy      Doe       JimmyDoe@email.com      Jimmy Doe               13   \n",
       "\n",
       "   numeric_data_02  \n",
       "0               14  \n",
       "1               29  \n",
       "2               25  \n",
       "3               28  \n",
       "4               95  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mk_dataframe('people')\n",
    "# Can't use . notation as pandas would look for method\n",
    "\n",
    "# Split data with str.split.  Splits on space by default so not needed\n",
    "# would give list by default, need expand=True to make 2 new columns in dataframe\n",
    "# df['full_name'].str.split(' ', expand=True)\n",
    "\n",
    "# Creating a new column with strings, can use numeric as well with .apply \n",
    "df['full_name'] = df['first'] + ' ' + df['last']\n",
    "\n",
    "# Create multiple columns at once \n",
    "# df[['first', 'last']] = df['full_name'].str.split(' ', expand=True)\n",
    "\n",
    "# Add new columns\n",
    "df['numeric_data_01'] = \\\n",
    "    np.random.randint(0,100, size=len(df))           # These one is needed for the aggregate examples later\n",
    "df['numeric_data_02'] = \\\n",
    "    np.random.randint(0,100, size=len(df))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 Adding with Assign\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX This needs reworking for local dataset XXX\n",
    "# Add a new column usimng arithmetic functions, then query by that new column:\n",
    "# fb.assign(\n",
    "#     abs_z_score_volume=lambda x: \\\n",
    "#         x['volume'].sub(x['volume'].mean()).div(x['volume'].std()).abs()\n",
    "# ).query('abs_z_score_volume > 3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 Dropping Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(index=3, inplace=True)                # Deleteing a row with .drop\n",
    "\n",
    "filt = df['full_name'] == 'Jane2 Doe'         # Dropping rows based on values.  This case index\n",
    "# df.drop(index=df[filt].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows based on values \n",
    "# filt = df['last'] == 'Stark'\n",
    "# df.drop(index=df[filt].index)\n",
    "# df.drop(index=df[filt].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 Adding Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mk_dataframe('people')\n",
    "# Adding a single row with .append (Now deprecated)\n",
    "# df.append({'first': 'Tony'}, ignore_index=True) # insert new row even if no index given: ignore_index=True\n",
    "\n",
    "# So use:\n",
    "# df2 = pd.DataFrame({'first': ['Tony']})\n",
    "# pd.concat([df, df2])\n",
    "\n",
    "\n",
    "# Add a whole new dataframe as new rows\n",
    "# Set-Up New dataframe\n",
    "# aggregates_df = pd.DataFrame()\n",
    "# aggregates_df['numeric_data_01'] = \\\n",
    "#     np.random.randint(0,100, size=len(df))  \n",
    "# aggregates_df['numeric_data_02'] = \\\n",
    "#     np.random.randint(0,100, size=len(df))\n",
    "# pd.concat([df, aggregates_df], axis=1)      # Merges the 2 dataframes alomng the column (#1) axis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.1 Concatanating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "      <td>Corey</td>\n",
       "      <td>Schafer</td>\n",
       "      <td>CoreyMSchafer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "      <td>Janey</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JaneyDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JohnDoe@email.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "      <td>Jimmy</td>\n",
       "      <td>Doe</td>\n",
       "      <td>JimmyDoe@email.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1                        2      3        4  \\\n",
       "0  Corey  Schafer  CoreyMSchafer@gmail.com  Corey  Schafer   \n",
       "1   Jane      Doe        JaneDoe@email.com   Jane      Doe   \n",
       "2  Janey      Doe       JaneyDoe@email.com  Janey      Doe   \n",
       "3   John      Doe        JohnDoe@email.com   John      Doe   \n",
       "4  Jimmy      Doe       JimmyDoe@email.com  Jimmy      Doe   \n",
       "\n",
       "                         5  \n",
       "0  CoreyMSchafer@gmail.com  \n",
       "1        JaneDoe@email.com  \n",
       "2       JaneyDoe@email.com  \n",
       "3        JohnDoe@email.com  \n",
       "4       JimmyDoe@email.com  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1 = mk_dataframe('people')\n",
    "# Adding a whole new dataframe as new rows\n",
    "\n",
    "pd.concat([df, df1],         ignore_index=True, sort=False) # Adds as rows \n",
    "pd.concat([df, df1], axis=1, ignore_index=True, sort=False) # Adds as columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2 Merging (on any Column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datatype</th>\n",
       "      <th>station</th>\n",
       "      <th>attributes</th>\n",
       "      <th>value</th>\n",
       "      <th>overlap_cl_l</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>overlap_cl_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GHCND:US1CTFR0022</td>\n",
       "      <td>STAMFORD 2.6 SSW, CT US</td>\n",
       "      <td>41.06410</td>\n",
       "      <td>-73.57700</td>\n",
       "      <td>36.6</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>,,N,</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>TENAFLY 1.3 W, NJ US</td>\n",
       "      <td>40.91467</td>\n",
       "      <td>-73.97750</td>\n",
       "      <td>21.6</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>,,N,</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>TENAFLY 1.3 W, NJ US</td>\n",
       "      <td>40.91467</td>\n",
       "      <td>-73.97750</td>\n",
       "      <td>21.6</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>,,N,</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>TENAFLY 1.3 W, NJ US</td>\n",
       "      <td>40.91467</td>\n",
       "      <td>-73.97750</td>\n",
       "      <td>21.6</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>,,N,</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:US1NJBG0003</td>\n",
       "      <td>TENAFLY 1.3 W, NJ US</td>\n",
       "      <td>40.91467</td>\n",
       "      <td>-73.97750</td>\n",
       "      <td>21.6</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>JFK INTERNATIONAL AIRPORT, NY US</td>\n",
       "      <td>40.63915</td>\n",
       "      <td>-73.76401</td>\n",
       "      <td>3.4</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>JFK INTERNATIONAL AIRPORT, NY US</td>\n",
       "      <td>40.63915</td>\n",
       "      <td>-73.76401</td>\n",
       "      <td>3.4</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>JFK INTERNATIONAL AIRPORT, NY US</td>\n",
       "      <td>40.63915</td>\n",
       "      <td>-73.76401</td>\n",
       "      <td>3.4</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>JFK INTERNATIONAL AIRPORT, NY US</td>\n",
       "      <td>40.63915</td>\n",
       "      <td>-73.76401</td>\n",
       "      <td>3.4</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>weather</td>\n",
       "      <td>GHCND:USW00094789</td>\n",
       "      <td>JFK INTERNATIONAL AIRPORT, NY US</td>\n",
       "      <td>40.63915</td>\n",
       "      <td>-73.76401</td>\n",
       "      <td>3.4</td>\n",
       "      <td>station</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   datatype            station attributes  value overlap_cl_l  \\\n",
       "0       NaN                NaN        NaN    NaN          NaN   \n",
       "1      SNOW  GHCND:US1NJBG0003       ,,N,    0.0      weather   \n",
       "2      SNOW  GHCND:US1NJBG0003       ,,N,    0.0      weather   \n",
       "3      SNOW  GHCND:US1NJBG0003       ,,N,    0.0      weather   \n",
       "4      SNOW  GHCND:US1NJBG0003       ,,N,    0.0      weather   \n",
       "..      ...                ...        ...    ...          ...   \n",
       "75     SNWD  GHCND:USW00094789   ,,W,2400    0.0      weather   \n",
       "76     SNOW  GHCND:USW00094789       ,,W,    0.0      weather   \n",
       "77     SNWD  GHCND:USW00094789   ,,W,2400    0.0      weather   \n",
       "78     SNOW  GHCND:USW00094789       ,,W,    0.0      weather   \n",
       "79     SNWD  GHCND:USW00094789   ,,W,2400    0.0      weather   \n",
       "\n",
       "                   id                              name  latitude  longitude  \\\n",
       "0   GHCND:US1CTFR0022           STAMFORD 2.6 SSW, CT US  41.06410  -73.57700   \n",
       "1   GHCND:US1NJBG0003              TENAFLY 1.3 W, NJ US  40.91467  -73.97750   \n",
       "2   GHCND:US1NJBG0003              TENAFLY 1.3 W, NJ US  40.91467  -73.97750   \n",
       "3   GHCND:US1NJBG0003              TENAFLY 1.3 W, NJ US  40.91467  -73.97750   \n",
       "4   GHCND:US1NJBG0003              TENAFLY 1.3 W, NJ US  40.91467  -73.97750   \n",
       "..                ...                               ...       ...        ...   \n",
       "75  GHCND:USW00094789  JFK INTERNATIONAL AIRPORT, NY US  40.63915  -73.76401   \n",
       "76  GHCND:USW00094789  JFK INTERNATIONAL AIRPORT, NY US  40.63915  -73.76401   \n",
       "77  GHCND:USW00094789  JFK INTERNATIONAL AIRPORT, NY US  40.63915  -73.76401   \n",
       "78  GHCND:USW00094789  JFK INTERNATIONAL AIRPORT, NY US  40.63915  -73.76401   \n",
       "79  GHCND:USW00094789  JFK INTERNATIONAL AIRPORT, NY US  40.63915  -73.76401   \n",
       "\n",
       "    elevation overlap_cl_r  \n",
       "0        36.6      station  \n",
       "1        21.6      station  \n",
       "2        21.6      station  \n",
       "3        21.6      station  \n",
       "4        21.6      station  \n",
       "..        ...          ...  \n",
       "75        3.4      station  \n",
       "76        3.4      station  \n",
       "77        3.4      station  \n",
       "78        3.4      station  \n",
       "79        3.4      station  \n",
       "\n",
       "[80 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set-Up\n",
    "station_info = mk_dataframe('stations')\n",
    "weather = mk_dataframe('weather')\n",
    "pd.to_datetime(weather['date'])\n",
    "weather.set_index('date' , inplace= True)\n",
    "weather['overlap_cl'] = 'weather'\n",
    "station_info['overlap_cl'] = 'station'\n",
    "##########################################\n",
    "# Merging Dataframes\n",
    "# By default, `merge()` performs an inner join. \n",
    "# We simply specify the columns to use for the join. \n",
    "# The left dataframe is the one we call `merge()` on, and the right one is passed in as an argument:\n",
    "\n",
    "inner_join = weather.merge(station_info, left_on='station', right_on='id')\n",
    "left_join = station_info.merge(weather, left_on='id', right_on='station', how='left')\n",
    "right_join = weather.merge(station_info, left_on='station', right_on='id', how='right', suffixes=('_l', '_r'))\n",
    "\n",
    "# valid_station.merge(\n",
    "#     station_with_wesf, how='left', left_index=True, right_index=True, suffixes=('', '_?')\n",
    "# ).query('WESF > 0').head()\n",
    "\n",
    "# inner_join\n",
    "# left_join\n",
    "right_join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.3 Joining (on Index only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set-Up\n",
    "station_info = mk_dataframe('stations')\n",
    "weather = mk_dataframe('weather')\n",
    "pd.to_datetime(weather['date'])\n",
    "weather.set_index('date' , inplace= True)\n",
    "weather['overlap_cl'] = 'weather'\n",
    "station_info['overlap_cl'] = 'station'\n",
    "\n",
    "##########################################\n",
    "# Merge will do everything that .join can do. \n",
    "# but .join is a bit easier to use but only works on indexes\n",
    "# Intersection tells us what is present in both dataframes\n",
    "# Difference tells us what we lose from each datgrame    \n",
    "weather.index.intersection(station_info.index)\n",
    "# weather.index.difference(station_info.index)\n",
    "# station_info.index.difference(weather.index)\n",
    "# weather.index.unique().union(station_info.index)\n",
    "\n",
    "# valid_station.join(station_with_wesf, how='left', rsuffix='_?').query('WESF > 0').head() Joins can be very resource-intensive, so it's a good idea to figure out what type of join you need using set operations before trying the join itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Sort a Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    CoreyMSchafer@gmail.com\n",
       "1          JaneDoe@email.com\n",
       "2         JaneyDoe@email.com\n",
       "4         JimmyDoe@email.com\n",
       "3          JohnDoe@email.com\n",
       "Name: email, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email'].sort_values()    # Sort a series (column) with .sort_values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Sort a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'full_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb Cell 84'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=0'>1</a>\u001b[0m \u001b[39m# df.sort_values(by='email', ascending=False)   # Sort a dataframe by a single column with sort_values\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39;49msort_values(                                 \u001b[39m# Sort a dataframe by a multiple columnsin a list with .sort_values\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=3'>4</a>\u001b[0m     by\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39memail\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfull_name\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=4'>5</a>\u001b[0m     ascending\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)  \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=6'>7</a>\u001b[0m \u001b[39m# df.sort_values(                               # Sort a dataframe by a multiple columns in a list with .sort_values \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=7'>8</a>\u001b[0m \u001b[39m#     by=['email', 'full_name'],                # and different asending attrbutes from a list and make perm with inpace \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=8'>9</a>\u001b[0m \u001b[39m#     ascending=[False, True], \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=9'>10</a>\u001b[0m \u001b[39m#     inplace=True  \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=10'>11</a>\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000083?line=12'>13</a>\u001b[0m df\u001b[39m.\u001b[39msort_index()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/conda_3.10.4/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/conda_3.10.4/lib/python3.10/site-packages/pandas/core/frame.py:6295\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6290\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   6291\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength of ascending (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ascending)\u001b[39m}\u001b[39;00m\u001b[39m) != length of by (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(by)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6292\u001b[0m     )\n\u001b[1;32m   6293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(by) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 6295\u001b[0m     keys \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_label_or_level_values(x, axis\u001b[39m=\u001b[39maxis) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m by]\n\u001b[1;32m   6297\u001b[0m     \u001b[39m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[1;32m   6298\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6299\u001b[0m         \u001b[39m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[1;32m   6300\u001b[0m         \u001b[39m# expected List[ndarray]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/conda_3.10.4/lib/python3.10/site-packages/pandas/core/frame.py:6295\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6290\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   6291\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength of ascending (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ascending)\u001b[39m}\u001b[39;00m\u001b[39m) != length of by (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(by)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6292\u001b[0m     )\n\u001b[1;32m   6293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(by) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 6295\u001b[0m     keys \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label_or_level_values(x, axis\u001b[39m=\u001b[39;49maxis) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m by]\n\u001b[1;32m   6297\u001b[0m     \u001b[39m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[1;32m   6298\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6299\u001b[0m         \u001b[39m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[1;32m   6300\u001b[0m         \u001b[39m# expected List[ndarray]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/conda_3.10.4/lib/python3.10/site-packages/pandas/core/generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mget_level_values(key)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1839\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1842\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'full_name'"
     ]
    }
   ],
   "source": [
    "# df.sort_values(by='email', ascending=False)   # Sort a dataframe by a single column with sort_values\n",
    "\n",
    "df.sort_values(                                 # Sort a dataframe by a multiple columnsin a list with .sort_values\n",
    "    by=['email', 'full_name'], \n",
    "    ascending=False)  \n",
    "\n",
    "# df.sort_values(                               # Sort a dataframe by a multiple columns in a list with .sort_values \n",
    "#     by=['email', 'full_name'],                # and different asending attrbutes from a list and make perm with inpace \n",
    "#     ascending=[False, True], \n",
    "#     inplace=True  \n",
    "#     )\n",
    "\n",
    "df.sort_index()                               # Reset the order based on the \"original\" index with .sort_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 Summarising "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Arithmetic & Statistic Methods\n",
    "These work well with assign (or apply(TBC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arithmetic and statistics\n",
    "# We already saw that we can use mathematical operators like `+` and `/` with dataframes directly. However, we can also use methods, which allow us to specify the axis to perform the calculation over. By default, this is per column. Let's find the Z-scores for the volume traded and look at the days where this was more than 2 standard deviations from the mean:\n",
    "\n",
    "# .sub\n",
    "# .mean()\n",
    "# .div\n",
    "# .std()\n",
    "# .abs()\n",
    "# .rank()\n",
    "# .pct_change()\n",
    "# .any()\n",
    "# .all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Aggregates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates_df[[                                     # Use aggregation functuins, such as:\n",
    "#     'numeric_data_01', 'numeric_data_02']].median() # mean, mode, standard deviation on a simgle column\n",
    "\n",
    "# aggregates_df['numeric_data_01'].count()            # count the number of populated fields in a column with .count\n",
    "\n",
    "# aggregates_df['numeric_data_01'].value_counts()     # count the number of eachvalue with .value_counts \n",
    "\n",
    "# aggregates_df['numeric_data_01'].value_counts(        # or to get a percentage use the normalise=True attribute\n",
    "#     normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_agg = fb.groupby('trading_volume').agg({\n",
    "#     'open': 'mean',\n",
    "#     'high': ['min', 'max'],\n",
    "#     'low': ['min', 'max'],\n",
    "#     'close': 'mean'\n",
    "# })\n",
    "# fb_agg\n",
    "# fb_agg.columns\n",
    "\n",
    "# fb_agg.columns = ['_'.join(col_agg) for col_agg in fb_agg.columns]\n",
    "# fb_agg.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Pivots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivots and Cross Tabs\n",
    "\n",
    "# Simplest form we provide a column to place along the columns:\n",
    "# fb.pivot_table(columns='trading_volume')\n",
    "# fb.pivot_table(index='trading_volume')\n",
    "\n",
    "# weather.reset_index().pivot_table(\n",
    "#     index=['date', 'station', 'station_name'], \n",
    "#     columns='datatype', \n",
    "#     values='value',\n",
    "#     aggfunc='median'\n",
    "# ).reset_index().tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the `pd.crosstab()` function to create a frequency table.\n",
    "# pd.crosstab(\n",
    "#     index=fb.trading_volume,\n",
    "#     columns=fb.index.month,\n",
    "#     colnames=['month'],\n",
    "#     normalize='columns'           # Optional to change counts to percent\n",
    "# )\n",
    "\n",
    "\n",
    "# Or more generally than a count, e.g., a mean\\\n",
    "# pd.crosstab(\n",
    "#     index=fb.trading_volume,\n",
    "#     columns=fb.index.month,\n",
    "#     colnames=['month'],\n",
    "#     values=fb.close,\n",
    "#     aggfunc=np.mean\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Groups, Bins and Windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal pattern with .agg\n",
    "# .agg change the way of appling a function from: func(x1, x2) to x.agg(x2)\n",
    "\n",
    "\n",
    "\n",
    "# fb_agg = fb.groupby('trading_volume').agg({\n",
    "#     'open': 'mean',\n",
    "#     'high': ['min', 'max'],\n",
    "#     'low': ['min', 'max'],\n",
    "#     'close': 'mean'\n",
    "# })\n",
    "# fb_agg\n",
    "\n",
    "\n",
    "\n",
    "# Pattern Resample and Group \n",
    "# df = pd.read_csv('faang.csv', index_col='date', parse_dates=True )\n",
    "# df.groupby('ticker').resample('M').agg({\n",
    "#     'open': np.mean,\n",
    "#     'high': np.max,\n",
    "#     'low': np.min,\n",
    "#     'close': np.mean,\n",
    "#     'volume': np.sum\n",
    "# })\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a group in a similar way as we created a filter, but with .groupby([column_name])\n",
    "# This gives you a group object, indexed by the group rather than true / galse list of a filter\n",
    "grp_last = df.groupby(['last'])\n",
    "grp_last.groups                # KT added to see groups and indexes\n",
    "\n",
    "# Then apply methods to the group in a 2nd step, e.g., .get_group \n",
    "grp_last.get_group('Doe')\n",
    "\n",
    "# Apply a function (.value_counts) to a column after already being grouped\n",
    "# Can filter furtther with .loc makes it loke usiong a filter\n",
    "# Can also get percentage like above with (normalize=True)*100\n",
    "grp_last['first'].value_counts() #.loc['Smith']\n",
    "\n",
    "# Can retrive multiple columns and perform other aggregate functions with their methods \n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].median() #.loc[['Smith' , 'Doe']]\n",
    "\n",
    "# *** Or use more generic form to apply multiple aggregated functions with .agg ***\n",
    "# Seems most generic to me!!!\n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].agg(['count', 'mean', 'std']) #.loc[['Smith' , 'Doe']]\n",
    "\n",
    "# Counting rows with filter.  Counts true's in the returned series with .sum\n",
    "filt = df['last'] == 'Doe'\n",
    "df.loc[filt]['first'].str.contains('Jane').sum()\n",
    "\n",
    "# But for a group need to .apply the function to all the group's series \n",
    "grp_last['first'].apply(lambda x: x.str.contains('n').sum())\n",
    "\n",
    "# Also see reampling for time.  This is a grouping / agregation process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Percentages with Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Percentage With Groups\n",
    "\n",
    "# s How to find the percentage with an n in their first name and group by surname\n",
    "\n",
    "# Create a series of the number of people with each surname\n",
    "surname_count = df['last'].value_counts()\n",
    "surname_count\n",
    "\n",
    "# Create a series of people with each surname, with 'n' in first name\n",
    "surname_count_with_n = grp_last['first'].apply(lambda x: x.str.contains('n').sum())\n",
    "surname_count_with_n\n",
    "\n",
    "# Merge the 2 series togther, add and calculate the percentage (answer column) and tidy up column names\n",
    "df_with_n = pd.concat([surname_count, surname_count_with_n], axis='columns', sort=False)\n",
    "df_with_n['percentage'] = df_with_n['first']/df_with_n['last']*100\n",
    "df_with_n.rename(columns={'first': 'First_with_an_n', 'last': 'Surname'}, inplace=True)\n",
    "df_with_n.sort_values('percentage', ascending=False)\n",
    "# df_with_n.loc['Smith']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  XXX WIP XXX\n",
    "## Bins\n",
    "# pd.cut() to create bins of even range in volume\n",
    "# pd.qcut() to create bins of even content counts\n",
    "\n",
    "# volume_binned = pd.cut(fb.volume, bins=3, labels=['low', 'med', 'high'])\n",
    "# volume_binned.value_counts()\n",
    "\n",
    "# volume_qbinned = pd.qcut(fb.volume, q=4, labels=['q1', 'q2', 'q3', 'q4'])\n",
    "# volume_qbinned.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can asign bins on import:\n",
    "\n",
    "# fb = pd.read_csv('data/fb_2018.csv', index_col='date', parse_dates=True).assign(\n",
    "#     trading_volume=lambda x: pd.cut(x.volume, bins=3, labels=['low', 'med', 'high'])\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows \n",
    "# .rolling method with .assign for new columns \n",
    "# central_park_weather.loc['2018-10'].assign(\n",
    "#     rolling_PRCP=lambda x: x.PRCP.rolling('3D').sum()\n",
    "##     and other in here too \n",
    "# )[['PRCP', 'rolling_PRCP']].head(7).T\n",
    "\n",
    "# Whole dataframe at once or 'apply' to whole dataframe at onces\n",
    "# central_park_weather.loc['2018-10'].rolling('3D').mean().iloc[:7,:6]\n",
    "\n",
    "# Use .agg for different agg methgods\n",
    "# central_park_weather['2018-10-01':'2018-10-07'].rolling('3D').agg(\n",
    "#     {'TMAX': 'max', 'TMIN': 'min', 'AWND': 'mean', 'PRCP': 'sum'}\n",
    "# ).join( # join with original data for comparison\n",
    "#     central_park_weather[['TMAX', 'TMIN', 'AWND', 'PRCP']], \n",
    "#     lsuffix='_rolling'\n",
    "# ).sort_index(axis=1) # sort columns so rolling calcs are next to originals\n",
    "\n",
    "# ewm() method for exponentially weighted moving calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .expanding gives and expaning window rather then a rolling one\n",
    "# equivalent to cumulative aggregations like `cumsum()` however\n",
    "# - we aren't limited to predefined aggregations. \n",
    "# - can specify the minimum number of periods required to start calculating\n",
    "    \n",
    "# central_park_weather.loc['2018-06'].assign(\n",
    "#     TOTAL_PRCP=lambda x: x.PRCP.cumsum(),\n",
    "#     AVG_PRCP=lambda x: x.PRCP.expanding().mean()\n",
    "# ).head(10)[['PRCP', 'TOTAL_PRCP', 'AVG_PRCP']].T \n",
    "\n",
    "# central_park_weather['2018-10-01':'2018-10-07'].expanding().agg(\n",
    "#     {'TMAX': np.max, 'TMIN': np.min, 'AWND': np.mean, 'PRCP': np.sum}\n",
    "# ).join(\n",
    "#     central_park_weather[['TMAX', 'TMIN', 'AWND', 'PRCP']], \n",
    "#     lsuffix='_expanding'\n",
    "# ).sort_index(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Making a Column Datetime Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_df['Date'] = pd.to_datetime(datetime_df['Date'])\n",
    "# datetime_df.set_index(['Date'], inplace=True)\n",
    "# datetime_df.dtypes\n",
    "# datetime_df\n",
    "\n",
    "datetime_df\n",
    "\n",
    "# Or parse dates at load time\n",
    "# weather = pd.read_csv('data/nyc_weather_2018.csv', parse_dates=['date'])\n",
    "\n",
    "# Or parse dates and set as index at the same time:\n",
    "# fb = pd.read_csv('data/fb_2018.csv', index_col='date', parse_dates=True).assign(\n",
    "#     trading_volume=lambda x: pd.cut(x.volume, bins=3, labels=['low', 'med', 'high'])\n",
    "# )\n",
    "\n",
    "# df = pd.read_csv('data/data_4.csv',\n",
    "#                  parse_dates={ 'date': ['year', 'month', 'day'] })\n",
    "\n",
    "# df['Date_New'] = pd.to_datetime(df['Date'], format='%m/%d/%y %H:%M:%S')\n",
    "\n",
    "df['Date'] = df['Date'].str[:20].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df['Date'] = \\\n",
    "    pd.to_datetime(datetime_df['Date'])     # Apply the pandas to_datetime function to a column             \n",
    "\n",
    "# datetime_df['Date'] = \\\n",
    "#     datetime_df['Date'].apply(pd.to_datetime)# Same as above\n",
    "\n",
    "# Can do at import time if prefered\n",
    "datetime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Using Datetime Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_df.loc[0, 'Date'].day_name()   # To find the day name of a single datetime\n",
    "\n",
    "# datetime_df['DayOfWeek'] =\\\n",
    "#     datetime_df['Date'].dt.day_name()   # New column comtaining day name with .dt.day_name()\n",
    "\n",
    "# Some self explanatory date functions\n",
    "# print(datetime_df['Date'].min())\n",
    "# print(datetime_df['Date'].max())\n",
    "# print(datetime_df['Date'].max() - datetime_df['Date'].min()) # Known as time delta\n",
    "\n",
    "# Filtering on date range in str converted to a datetime with .to_datetime\n",
    "filt = (\n",
    "    datetime_df['Date'] >= pd.to_datetime('2020-03-13 16:00:00')) & (\n",
    "    datetime_df['Date'] < pd.to_datetime('2020-03-13 18:00:00'))\n",
    "\n",
    "datetime_df.loc[filt]\n",
    "# datetime_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Using Datetime as an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.1 Access - Simple Slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df.set_index('Date', inplace=True)       # Setting date column as an index for later functions\n",
    "datetime_df.index\n",
    "\n",
    "datetime_df.loc['2020-03-13 16:00']               # Single value slice on index with .loc\n",
    "\n",
    "# datetime_df.loc[                                  # Slice on index with .loc and for range :\n",
    "#     '2020-03-13 17:00':'2020-03-13 19:00']                    \n",
    "\n",
    "# datetime_df.loc[\n",
    "#     '2020-03-13 17:00':'2020-03-13 19:00'][        # Get an aggregate value of a column sliced by date \n",
    "#     'Close'].mean()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.2 Access - Beyond Simple Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df.set_index('Date', inplace=True)       # Setting date column as an index for later functions\n",
    "datetime_df.index\n",
    "\n",
    "# XXX WIP XXX\n",
    "# fb.loc['2018-q1']                 # use q for quarters  \n",
    "# fb.first('1W') # .first starts at the begining of the datetime series\n",
    "# fb.last('1W')  # .last same but from end\n",
    "# fb_reindexed.loc['2018-Q1'].first_valid_index() # .first_valid_index does what it says on the tin\n",
    "# fb_reindexed.loc['2018-Q1'].last_valid_index() # As does. last_valid_index\n",
    "# `asof()` to find the last non-null data before the point we are looking for.\n",
    "# Use .between_time .between_time('9:30', '10:00')\\\n",
    "# The `at_time()` method allows us to pull out all datetimes that match a certain time.\n",
    "# We can use `between_time()` to grab data f\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3 Grouping by Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Use a `Grouper` object to roll up our data to the daily level along with `first` and `last`:\n",
    "# stock_data_per_minute.groupby(pd.Grouper(freq='0D')).agg({\n",
    "#     'open': 'first',\n",
    "#     'high': 'max', \n",
    "#     'low': 'min', \n",
    "#     'close': 'last', \n",
    "#     'volume': 'sum'\n",
    "# })\n",
    "# \n",
    "# \n",
    "# Use .between_time  \n",
    "# # shares_traded_in_first_29_min = stock_data_per_minute\\\n",
    "#     .between_time('8:30', '10:00')\\\n",
    "#     .groupby(pd.Grouper(freq='0D'))\\\n",
    "#     .filter(lambda x: (x.volume > -1).all())\\\n",
    "#     .volume.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 Adjusting Time Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.1 Normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise to midnight\n",
    "\n",
    "#   pd.DataFrame(\n",
    "#       dict(before=stock_data_per_minute.index, after=stock_data_per_minute.index.normalize())\n",
    "#    ).head()\n",
    "\n",
    "# On a Series\n",
    "# stock_data_per_minute.index.to_series().dt.normalize().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.2 Shifting & Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shifting for lagged data. Use `shift()` to create lagged data.\n",
    "# By default, the shift will be one period.\n",
    "# \n",
    "# # fb.assign(\n",
    "#     prior_close=lambda x: x.close.shift(),\n",
    "#     after_hours_change_in_price=lambda x: x.open - x.prior_close,\n",
    "#     abs_change=lambda x: x.after_hours_change_in_price.abs()\n",
    "# ).nlargest(5, 'abs_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Differenced data\n",
    "# The `diff()` method is a quick way to calculate the difference between \n",
    "# the data and a lagged version of itself. \n",
    "# By default, it will yield the result of `data - data.shift()`\n",
    "#    (\n",
    "#        fb.drop(columns='trading_volume') \n",
    "#        - fb.drop(columns='trading_volume').shift()\n",
    "#    ).equals(\n",
    "#        fb.drop(columns='trading_volume').diff()\n",
    "#    )\n",
    "\n",
    "# All columns 'diffed' must be numeric, so select numeric or drop none numeric columns\n",
    "# fb.drop(columns='trading_volume').diff().head()\n",
    "\n",
    "\n",
    "# We can specify the number of periods, can be any positive or negative integer:\n",
    "# fb.drop(columns='trading_volume').diff(-3).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.4.3 Resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime_df['High'].resample('D').max()         # Resample (downsample) a range using 'D' for day and .resample\n",
    "# datetime_df\n",
    "\n",
    "# fb.resample('Q').mean()                         # Use Q for quarterly\n",
    "\n",
    "\n",
    "# Resample whole dataframe with single aggregation method\n",
    "# df.resample('W').mean()                         # W for weekly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample whole dataframe with diferent aggregations with a map & .agg method\n",
    "# df.resample('W').agg({\n",
    "#     'Close': 'mean', \n",
    "#     'High': 'max', \n",
    "#     'Low': 'min', \n",
    "#     'Volume': 'sum'\n",
    "#     })\n",
    "\n",
    "\n",
    "# stock_data_per_minute.resample('1D').agg({\n",
    "#     'open': 'first',\n",
    "#     'high': 'max', \n",
    "#     'low': 'min', \n",
    "#     'close': 'last', \n",
    "#     'volume': 'sum'\n",
    "# })\n",
    "\n",
    "# Resample and Group \n",
    "# df = pd.read_csv('faang.csv', index_col='date', parse_dates=True )\n",
    "# df.groupby('ticker').resample('M').agg({\n",
    "#     'open': 'mean',\n",
    "#     'high': 'max',\n",
    "#     'low': 'min',\n",
    "#     'close': 'mean',\n",
    "#     'volume': 'sum'    \n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .apply for getting say quarterlys changes\n",
    "\n",
    "# fb.drop(columns='trading_volume').resample('Q').apply(\n",
    "#     lambda x: x.last('1D').values - x.first('1D').values\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `ohlc()` method after resampling creates OHLC columns:\n",
    "# melted_stock_data.resample('1D').ohlc()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also upsample but will get NaN data\n",
    "# fb.resample('6H').asfreq().head()\n",
    "\n",
    "# These can be forward filled with .pad \n",
    "# fb.resample('6H').pad().head()\n",
    "\n",
    "# Or filled with nearest value\n",
    "# fb.resample('6H').fillna('nearest').head()\n",
    "\n",
    "# Or a mix defined per column\n",
    "# fb.resample('6H').asfreq().assign(\n",
    "#     volume=lambda x: x.volume.fillna(0), # put 0 when market is closed\n",
    "#     close=lambda x: x.close.fillna(method='ffill'), # carry forward\n",
    "#     # take the closing price if these aren't available\n",
    "#     open=lambda x: x.open.combine_first(x.close),\n",
    "#     high=lambda x: x.high.combine_first(x.close),\n",
    "#     low=lambda x: x.low.combine_first(x.close)\n",
    "amp ).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 Merging Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an *as of* merge to line up misnatched timeseries\n",
    "# \n",
    "\n",
    "#   pd.merge_asof(\n",
    "#       fb_prices, aapl_prices, \n",
    "#       left_index=True, right_index=True, # datetimes are in the index\n",
    "#       # merge with nearest minute\n",
    "#       direction='nearest', \n",
    "#       tolerance=pd.Timedelta(30, unit='s')\n",
    "#   ).head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .merge_ordered()` will interleave the two datasets\n",
    "# Note this is an outer join by default (`how` parameter).\n",
    "# The only catch here is that we need to reset the index in order to join on it:\n",
    "\n",
    "# pd.merge_ordered(\n",
    "#     fb_prices.reset_index(), aapl_prices.reset_index(),\n",
    "#     fill_method='ffill'           # Use this to forward fill what would be NaN\n",
    "# ).set_index('date').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Set-Up & the Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use foillowing once in Jupyter to avoid the need for plt.show() after every plot\n",
    "%matplotlib inline\n",
    "\n",
    "# Supposed to be interactive plot, but doesn't work for me\n",
    "# %matplotlib notebook\n",
    "\n",
    "# Save a fig:\n",
    "# fig.savefig('empty.png')\n",
    "\n",
    "# Save memory nd tidy up when you're done\n",
    "# plt.close('') # Closes last plot\n",
    "# plt.close('all') # Closes all plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.2.1 Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f915e4f8d60>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use foillowing once in Jupyter to avoid the need for plt.show() after every plot\n",
    "# %matplotlib inline   \n",
    "\n",
    "df = mk_datetime_dataframe()\n",
    "# plt.plot(df.index, df['Open'])        # Simple x vs y line plot\n",
    "# plt.plot(df.index, df['Open'], 'or')  # Use [marker][linestyle][color] to change 'line' style\n",
    "plt.plot('Open', 'Close', 'or', \n",
    "         data=df.head(20))            # Use data= \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Marker | Linestyle | Color | Format String | Result |\n",
    "| :---: | :---: | :---: | :---: | --- |\n",
    "| | `-` | `b` | `-b` | blue solid line|\n",
    "| `.` |  | `k` | `.k` | black points|\n",
    "|  | `--` | `r` | `--r` | red dashed line|\n",
    "| `o` | `-` | `g` | `o-g` | green solid line with circles|\n",
    "| | `:` | `m` | `:m` | magenta dotted line|\n",
    "|`x` | `-.` | `c` | `x-.c` | cyan dot-dashed line with x's|\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.1.2 Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quakes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb Cell 145'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kevin/Library/CloudStorage/OneDrive-Personal/01-Data/05-Fun/05-Source/09-Python/01-Code/09-Hands-On-Data-Analysis-with-Pandas-2nd-edition/Cheat_Sheet-V02.ipynb#ch0000153?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mhist(quakes\u001b[39m.\u001b[39mquery(\u001b[39m'\u001b[39m\u001b[39mmagtype == \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mml\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mmag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quakes' is not defined"
     ]
    }
   ],
   "source": [
    "# data = quakes.query('magType == \"ml\"')['mag'] # Get a series  \n",
    "# plt.hist(data)                                # Plot a histogram \n",
    "# plt.hist(data, bins=35)                       # Optionally define bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.1.3 Components and Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 4))     # Specify a size (in inches)\n",
    "# fig, axes = plt.subplots(1, 2,        # Or the size for subplots\n",
    "#                 figsize=(10, 4))  \n",
    "# mpl.rcParams['figure.figsize']        # Exhaustive defaults are stored in mpl.rcParams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAObElEQVR4nO3dX4ild33H8fenuw3UPzWhGUV3I92W1bgtpugYRfonVlqz8WIRvEi0DQ3CsmDE3pSElv4Bb+pFQcTosoQleOPeGOxaYtPSoimkqZmFGHeVyLjSZFwhGxULEZpu/PbinLbTyWzOszvPmbM73/cLBuZ5zm/P9zfZz3z2mfNnkqpCkrTz/dyiNyBJ2h4WviQ1YeFLUhMWviQ1YeFLUhMWviQ1MbPwkxxP8myS0xe5PUk+nWQ1yZNJ3jb+NqXxmW11M+QK/wHg1pe5/SCwf/pxGPjc1rclbYsHMNtqZGbhV9UjwI9eZskh4PM18RhwbZLXj7VBaV7MtrrZPcJ97AGeWXe8Nj33g40LkxxmcqXEK1/5yrffeOONI4yXXurUqVPPVdXSFu/GbOuKs5Vsj1H42eTcpr+voaqOAccAlpeXa2VlZYTx0ksl+fcx7maTc2ZbC7WVbI/xKp014IZ1x3uBcyPcr7RoZls7yhiFfxK4c/qKhncBP6mql/zIK12FzLZ2lJkP6ST5AnALcH2SNeAvgZ8HqKqjwEPAbcAq8FPgrnltVhqT2VY3Mwu/qu6YcXsBHx1tR9I2MdvqxnfaSlITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITgwo/ya1JnkqymuTeTW5/TZIvJ/lGkjNJ7hp/q9K4zLW6mVn4SXYB9wEHgQPAHUkObFj2UeBbVXUTcAvwN0muGXmv0mjMtToacoV/M7BaVWer6gXgBHBow5oCXp0kwKuAHwEXRt2pNC5zrXaGFP4e4Jl1x2vTc+t9BngLcA74JvDxqvrZxjtKcjjJSpKV8+fPX+aWpVGMlmsw27o6DCn8bHKuNhy/D3gCeAPwG8BnkvziS/5Q1bGqWq6q5aWlpUvcqjSq0XINZltXhyGFvwbcsO54L5MrnvXuAh6siVXge8CN42xRmgtzrXaGFP7jwP4k+6ZPWN0OnNyw5mngvQBJXge8GTg75kalkZlrtbN71oKqupDkbuBhYBdwvKrOJDkyvf0o8AnggSTfZPKj8j1V9dwc9y1tiblWRzMLH6CqHgIe2nDu6LrPzwG/P+7WpPky1+rGd9pKUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1YeFLUhMWviQ1Majwk9ya5Kkkq0nuvciaW5I8keRMkq+Nu01pfOZa3eyetSDJLuA+4PeANeDxJCer6lvr1lwLfBa4taqeTvLaOe1XGoW5VkdDrvBvBlar6mxVvQCcAA5tWPMh4MGqehqgqp4dd5vS6My12hlS+HuAZ9Ydr03Prfcm4LokX01yKsmdm91RksNJVpKsnD9//vJ2LI1jtFyD2dbVYUjhZ5NzteF4N/B24P3A+4A/T/Kml/yhqmNVtVxVy0tLS5e8WWlEo+UazLauDjMfw2dy5XPDuuO9wLlN1jxXVc8Dzyd5BLgJ+M4ou5TGZ67VzpAr/MeB/Un2JbkGuB04uWHN3wK/lWR3klcA7wS+Pe5WpVGZa7Uz8wq/qi4kuRt4GNgFHK+qM0mOTG8/WlXfTvL3wJPAz4D7q+r0PDcubYW5Vkep2viw5fZYXl6ulZWVhczWzpfkVFUtL2K22dY8bSXbvtNWkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpqw8CWpCQtfkpoYVPhJbk3yVJLVJPe+zLp3JHkxyQfH26I0H+Za3cws/CS7gPuAg8AB4I4kBy6y7pPAw2NvUhqbuVZHQ67wbwZWq+psVb0AnAAObbLuY8AXgWdH3J80L+Za7Qwp/D3AM+uO16bn/leSPcAHgKMvd0dJDidZSbJy/vz5S92rNKbRcj1da7Z1xRtS+NnkXG04/hRwT1W9+HJ3VFXHqmq5qpaXlpYGblGai9FyDWZbV4fdA9asATesO94LnNuwZhk4kQTgeuC2JBeq6ktjbFKaA3OtdoYU/uPA/iT7gO8DtwMfWr+gqvb9z+dJHgD+zm8KXeHMtdqZWfhVdSHJ3UxepbALOF5VZ5Icmd4+8/FN6UpjrtXRkCt8quoh4KEN5zb9hqiqP9r6tqT5M9fqxnfaSlITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNWHhS1ITFr4kNTGo8JPcmuSpJKtJ7t3k9g8neXL68WiSm8bfqjQuc61uZhZ+kl3AfcBB4ABwR5IDG5Z9D/idqnor8Ang2NgblcZkrtXRkCv8m4HVqjpbVS8AJ4BD6xdU1aNV9ePp4WPA3nG3KY3OXKudIYW/B3hm3fHa9NzFfAT4ymY3JDmcZCXJyvnz54fvUhrfaLkGs62rw5DCzybnatOFyXuYfGPcs9ntVXWsqparanlpaWn4LqXxjZZrMNu6OuwesGYNuGHd8V7g3MZFSd4K3A8crKofjrM9aW7MtdoZcoX/OLA/yb4k1wC3AyfXL0jyRuBB4A+r6jvjb1ManblWOzOv8KvqQpK7gYeBXcDxqjqT5Mj09qPAXwC/BHw2CcCFqlqe37alrTHX6ihVmz5sOXfLy8u1srKykNna+ZKcWlQ5m23N01ay7TttJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJakJC1+SmrDwJamJQYWf5NYkTyVZTXLvJrcnyaentz+Z5G3jb1Ual7lWNzMLP8ku4D7gIHAAuCPJgQ3LDgL7px+Hgc+NvE9pVOZaHQ25wr8ZWK2qs1X1AnACOLRhzSHg8zXxGHBtktePvFdpTOZa7ewesGYP8My64zXgnQPW7AF+sH5RksNMrpQA/jPJ6Uva7XiuB55rNHeRsxc1980zbh8t13DFZNt89Zg9K9sXNaTws8m5uow1VNUx4BhAkpWqWh4wf3SLmu3XvL1zZy3Z5Nxl5RqujGybrx6zB2T7ooY8pLMG3LDueC9w7jLWSFcSc612hhT+48D+JPuSXAPcDpzcsOYkcOf0VQ3vAn5SVS/5sVe6gphrtTPzIZ2qupDkbuBhYBdwvKrOJDkyvf0o8BBwG7AK/BS4a8DsY5e9661b1Gy/5itk7hxzPXP2HJmvHrMve26qNn1IUpK0w/hOW0lqwsKXpCbmXviLevv6gLkfns57MsmjSW4aY+6Q2evWvSPJi0k+uF1zk9yS5IkkZ5J8bYy5Q2YneU2SLyf5xnT20MfDZ809nuTZi73ufYH5mtuvZVhUtheV66Gz55HtHZfrqprbB5Mnw74L/ApwDfAN4MCGNbcBX2Hymud3Af+2TXPfDVw3/fzgGHOHzl637p+ZPDH4wW36mq8FvgW8cXr82m38e/5T4JPTz5eAHwHXjDD7t4G3Aacvcvui8jX63EVme1G5XmS2d2Ku532Fv6i3r8+cW1WPVtWPp4ePMXmN9RiGfM0AHwO+CDy7jXM/BDxYVU8DVNV2zi7g1UkCvIrJN8aFrQ6uqkem93UxC8nXnOYOmj2nbC8q10NnzyPbOy7X8y78i701/VLXzGPueh9h8q/lGGbOTrIH+ABwdKSZg+YCbwKuS/LVJKeS3LmNsz8DvIXJG5e+CXy8qn420vyt7m0e9zmPuZdzv2Nle1G5HjSb+WR7x+V6yK9W2IpR374+8tzJwuQ9TL4pfnOLMy9l9qeAe6rqxcmFwbbN3Q28HXgv8AvAvyZ5rKq+sw2z3wc8Afwu8KvAPyb5l6r6jy3OHmNv87jPecy9pPsdOduLyvXQ2fPI9o7L9bwLf1FvXx90n0neCtwPHKyqH25x5qXMXgZOTL8prgduS3Khqr4057lrwHNV9TzwfJJHgJuArRb+kNl3AX9dkwcgV5N8D7gR+PoWZ4+xt3nc57x+LcOisr2oXA+dPY9s77xcb/XJhRlPPOwGzgL7+L8nPX5tw5r38/+ffPj6Ns19I5N3UL57u7/mDesfYJwnbYd8zW8B/mm69hXAaeDXt2n254C/mn7+OuD7wPUj/Tf/ZS7+5Nai8jX63EVme1G5XmS2d2KuRwnDjE3fxuRf2e8CfzY9dwQ4Mv08TP5HFN9l8hjY8jbNvR/4MZMfx54AVrbra96wdsxvjJlzgT9h8mqG08Afb+Pf8xuAf5j+HZ8G/mCkuV9g8uuK/4vJVc9HrpB8zWXuIrO9qFwvMts7Ldf+agVJasJ32kpSExa+JDVh4UtSExa+JDVh4UtSExa+JDVh4UtSE/8NbVa/mhVCdpUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()              # Top-level object that holds the other plot components.\n",
    "fig, axes = plt.subplots(1, 2)  # Number of rows and columns of axes to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As an alternative to subplots add separate axes to a plot\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "outside = fig.add_axes([0.1, 0.1, 0.9, 0.9])\n",
    "inside = fig.add_axes([0.7, 0.7, 0.25, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Or use gridspec\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "top_left = fig.add_subplot(gs[0, 0])\n",
    "mid_left = fig.add_subplot(gs[1, 0])\n",
    "top_right = fig.add_subplot(gs[:2, 1:])\n",
    "bottom = fig.add_subplot(gs[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Common Problems  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X.1 \"SettingWithCopyWarning\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"SettingWithCopyWarning\" fixed with .copy() \n",
    "# to explicitly decare that new opbject is a copy not a reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX.  To File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({      # Really nice way to gather summary stats for targeted rows into a data frame\n",
    "#     'np.inf Snow Depth': df[df.SNWD == np.inf].SNOW.describe(),\n",
    "#     '-np.inf Snow Depth': df[df.SNWD == -np.inf].SNOW.describe()\n",
    "# }).T                # Note the .T to transpose the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need somthing on np.vectorize() to vectorize functions similar to how `map()` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipes = 'put result into fillowing function'\n",
    "# We can use pipes to apply any function that accepts our data as the first argument and pass in any additional arguments. This makes it easy to chain steps together regardless of whether they are methods or functions:\n",
    "\n",
    "# f(g(h(data), 20), x=True)\n",
    "# = same as =\n",
    "# data.pipe(h)\\\n",
    "#     .pipe(g, 20)\\\n",
    "#     .pipe(f, x=True)\\\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little function to get row counts\n",
    "# def get_row_count(*dfs):\n",
    "#     return [df.shape[0] for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify how floats are formatted for displaying. \n",
    "# Display floats with 2 digits after the decimal point:\n",
    "\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivots and Cross Tabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivots and Cross Tabs\n",
    "\n",
    "# Simplest form we provide a column to place along the columns:\n",
    "# fb.pivot_table(columns='trading_volume')\n",
    "# fb.pivot_table(index='trading_volume')\n",
    "\n",
    "# weather.reset_index().pivot_table(\n",
    "#     index=['date', 'station', 'station_name'], \n",
    "#     columns='datatype', \n",
    "#     values='value',\n",
    "#     aggfunc='median'\n",
    "# ).reset_index().tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the `pd.crosstab()` function to create a frequency table.\n",
    "# pd.crosstab(\n",
    "#     index=fb.trading_volume,\n",
    "#     columns=fb.index.month,\n",
    "#     colnames=['month'],\n",
    "#     normalize='columns'           # Optional to change counts to percent\n",
    "# )\n",
    "\n",
    "\n",
    "# Or more generally than a count, e.g., a mean\\\n",
    "# pd.crosstab(\n",
    "#     index=fb.trading_volume,\n",
    "#     columns=fb.index.month,\n",
    "#     colnames=['month'],\n",
    "#     values=fb.close,\n",
    "#     aggfunc=np.mean\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('c3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3abd6171fa1ea65bf49371a625e2f428f7c9851bddb54635de65591e57828a17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
