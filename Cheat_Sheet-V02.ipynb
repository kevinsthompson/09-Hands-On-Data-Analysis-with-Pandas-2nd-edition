{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kevin's Pandas' Crib Sheet\n",
    "\n",
    "This is a consolidation notes and examples from:\n",
    "> Coreys MSchafer's Pandas videos [here](https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS) \n",
    "\n",
    "and \n",
    "> Hands on Data Analysis by xxx\n",
    "\n",
    "Version 2.0W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people={'first': ['Corey', 'Jane', 'Janey', 'John', 'Jimmy'], 'last': ['Schafer', 'Doe', 'Doe', 'Doe', 'Doe'], 'email': ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JaneyDoe@email.com', 'JohnDoe@email.com', 'JimmyDoe@email.com']}\n"
     ]
    }
   ],
   "source": [
    "people = {\n",
    "    'first': ['Corey', 'Jane', 'Janey', 'John', 'Jimmy'], \n",
    "    'last': ['Schafer', 'Doe', 'Doe', 'Doe', 'Doe'], \n",
    "    'email': [\"CoreyMSchafer@gmail.com\", 'JaneDoe@email.com', 'JaneyDoe@email.com','JohnDoe@email.com', 'JimmyDoe@email.com']\n",
    "}\n",
    "print(f'{people=}')\n",
    "# print(people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick Overview of the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(people)\n",
    "# df.info()             # Overview of the dataframe\n",
    "# df.columns            # List column names\n",
    "# df.describe()           # Quick summart of the frame, best for wide format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JaneyDoe@email.com',\n",
      "       'JohnDoe@email.com', 'JimmyDoe@email.com'],\n",
      "      dtype='object', name='email')\n"
     ]
    }
   ],
   "source": [
    "# Set a new index and keep it set with inplace.  \n",
    "# Indexes don't have to be unique (?!)\n",
    "df.set_index('email', inplace=True)     # Set a column to be an index\n",
    "print(df.index)\n",
    "df.reset_index(inplace=True)            # Reset row indexes to (hand to 'save'a column used a an index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accessing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df                                # Simple access\n",
    "# df['email']                       # Access single column\n",
    "# df[['last', 'email']]             # Access multiple columns by using a list (a list within the list)i\n",
    "# df.iloc[[0, 1], 2]                # Access by integer reference / index by using .iloc.  .loc and iloc takes row index first\n",
    "# df.loc[[0, 1], ['email', 'last']] # As above \n",
    "df.loc['CoreyMSchafer@gmail.com', 'last'] # Access by text index name and column name using .loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering\n",
    "2 part process to filtering.  1) Set filter 2) Apply filter\n",
    "\n",
    "_But can't use 'filter' as a variable name it's reserved_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df['last'] == 'Schafer') | (df['first'] == 'John')  # 1) Set filter.  An exampe of an 'or' '|' filter\n",
    "df.loc[filt, 'email']                                       # 2) Apply filter \n",
    "df.loc[~filt, 'email']                                      # 3) Or apply inverse of filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Updating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Update Column Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['email', 'first_name', 'last_name']           # Rename all columns \n",
    "\n",
    "df.rename(                                                  # Rename specific columns using .rename\n",
    "    columns={\n",
    "        'first_name': 'first', 'last_name': 'last'\n",
    "        }, inplace=True\n",
    "    ) \n",
    " \n",
    "df.columns = [x.upper() for x in df.columns]                # Rename all columns by an inline comprehension .columns\n",
    "df.columns = [x.lower() for x in df.columns]                #reset for later\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Update values - Direct Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Whole Rows\n",
    "df.loc[3] = ['John2Smith@email.com', 'John2', 'Smith']              # Update whole row with .loc\n",
    "df.loc[2, ['last', 'email']] = ['Smith', 'janeysmith@email.com']    # update specific columns of a row with .loc\n",
    "\n",
    "# Update whole columns \n",
    "df['email'] = df['email'].str.lower()                               # Update whole column with string object method with.str.x\n",
    "\n",
    "# Update based on filter \n",
    "filt = (df['email'] == 'John2Smith@email.com')                      # Update cells based on a filter with .loc\n",
    "# df[filt]['last'] = 'Smith'                                        # DON'T do this, it won't work\n",
    "df.loc[filt, 'first'] = 'Johnny'                                    # THIS will\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Updating Values - with Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four Functions:\n",
    "- `apply`\n",
    "- `map`\n",
    "- `applymap` &\n",
    "- `replace`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 `apply` a function to an object (dataframe or series) and get a series as a result\n",
    "- Object can be a series (by defauly a column) \n",
    "- Object can be a dataframe in which case it's applied to each series (column) for a single result for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email    CoreyMSchafer@gmail.com\n",
       "first                      Corey\n",
       "last                         Doe\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying to a column\n",
    "# df['email'].apply(len)            # `apply` the `len` function to the email column\n",
    "\n",
    "# def update_email(email):          # 'Apply' your own function\n",
    "#     return email.upper()\n",
    "# df['email'].apply(update_email) \n",
    "\n",
    "# df['email'].apply(                # 'Apply' a your own inline (LAMBDA) function \n",
    "#     lambda x: x.lower()           # to a whole column and get a series as a result\n",
    "#     )  \n",
    "\n",
    "# # When applied to a dataframe 'apply' is applied across each series\n",
    "# df.apply(len) #or df.apply(len, axis='columns') or df.apply(len, axis='rows')   \n",
    "# df.apply(pd.Series.min)           # Returns the minimum (first in alaphs) in each column\n",
    "\n",
    "df.apply(                           # Applying a Lambda function to each series\n",
    "    lambda x: x.min()\n",
    "    )     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 `applymap` a function to a dataframe and get a dataframe as a result.  \n",
    "Applied elementwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coreymschafer@gmail.com</td>\n",
       "      <td>corey</td>\n",
       "      <td>schafer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>janedoe@email.com</td>\n",
       "      <td>jane</td>\n",
       "      <td>doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>janeydoe@email.com</td>\n",
       "      <td>janey</td>\n",
       "      <td>doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>johndoe@email.com</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jimmydoe@email.com</td>\n",
       "      <td>jimmy</td>\n",
       "      <td>doe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     email  first     last\n",
       "0  coreymschafer@gmail.com  corey  schafer\n",
       "1        janedoe@email.com   jane      doe\n",
       "2       janeydoe@email.com  janey      doe\n",
       "3        johndoe@email.com   john      doe\n",
       "4       jimmydoe@email.com  jimmy      doe"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.applymap(len)\n",
    "df.applymap(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3 `map` a series and get a series as a result.  \n",
    "Replaces __all__ elements in series  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .map only works on a series. Use like a vlookup\n",
    "# Use it to subsitute one value for another via a lookup dictionary.\n",
    "# Unsubtituted vales replaced by NaN\n",
    "df['first'].map({'Corey': 'Chris', 'Jane': 'Mary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .replace works like map but leaves unsubsittuted values untouched (not NaN)\n",
    "df['first'] = df['first'].replace({'Corey': 'Corey2', 'Jane': 'Jane2'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesson 6 Add & Remove Rows and Columns\n",
    "\n",
    "# Creating a new column with strings, can use numeric as well with .apply \n",
    "# Can't use . notation as pandas would look for methd\n",
    "df['full_name'] = df['first'] + ' ' + df['last']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with .drop like a db\n",
    "df.drop(columns=['first', 'last'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data with str.split \n",
    "# splits on space by default so not needed\n",
    "df['full_name'].str.split(' ', expand=True)\n",
    "# would give list by default, need expand=True to make 2 new columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple columns at once \n",
    "df[['first', 'last']] = df['full_name'].str.split(' ', expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a single row with .append\n",
    "# df.append({'first': 'Tony'}, ignore_index=True)\n",
    "# insert new row even if no index given: ignore_index=True\n",
    "\n",
    "# Above from video now deprecated, so my method below:\n",
    "df2 = pd.DataFrame({'first': ['Tony']})\n",
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for adding a whole new dataframe\n",
    "people = {\n",
    "    'first': ['Tony', 'Steve'], \n",
    "    'last': ['Stark', 'Rogers'], \n",
    "    'email': ['IronMan@avenge.com', 'Cap@avenge.com']\n",
    "}\n",
    "df2 = pd.DataFrame(people)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a whole new dataframe\n",
    "df = df.append(df2, ignore_index=True, sort=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleteing a row with .drop\n",
    "df.drop(index=6, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows based on values \n",
    "filt = df['last'] == 'Stark'\n",
    "df.drop(index=df[filt].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lesson 7 Sorting Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a dataframe by a single column with sort_values\n",
    "df.sort_values(by='last', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a dataframe by a multiple columnsin a list with .sort_values\n",
    "df.sort_values(by=['last', 'first'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a dataframe by a multiple columns in a list with .sort_values \n",
    "# and different asending attrbutes from a list and make perm with inpace \n",
    "df.sort_values(by=['last', 'first'], ascending=[False, True], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the order based on teh \"original\" index with .sort_index\n",
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a series (column) with .sort_values \n",
    "df['last'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lessson 8 Aggregates\n",
    "# Corey uses large data set, I'm just adding extra numeric colums to the existing one.\n",
    "df['numeric_data_01'] = np.random.randint(0,100, size=len(df))\n",
    "df['numeric_data_02'] = np.random.randint(0,100, size=len(df))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use aggregation functuins, such as mean, mode, standard deviation etc on a simgle column\n",
    "df[['numeric_data_01', 'numeric_data_02']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or get anb overview of all numeric columns with .describe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of populated fields in a column with .count\n",
    "df['last'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of eachvalue with .value_counts \n",
    "df['last'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or to get a percentage use the normalise=True attribute\n",
    "df['last'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups\n",
    "# Create a group in a similar way as we created a filter, but with .groupby([column_name])\n",
    "# This gives you a group object, indexed by the group rather than true / galse list of a filter\n",
    "grp_last = df.groupby(['last'])\n",
    "grp_last.groups                # KT added to see groups and indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then apply methods to the group in a 2nd step, e.g., .get_group \n",
    "grp_last.get_group('Smith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a function (.value_counts) to a column after already being grouped\n",
    "# Can filter furtther with .loc makes it loke usiong a filter\n",
    "# Can also get percentage like above with (normalize=True)*100\n",
    "grp_last['first'].value_counts() #.loc['Smith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can retrive multiple columns and perform other aggregate functions with their methods \n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].median() #.loc[['Smith' , 'Doe']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Or use more generic form to apply multiple aggregated functions with .agg ***\n",
    "# Seems most generic to me!!!\n",
    "grp_last[['numeric_data_01', 'numeric_data_02']].agg(['count', 'mean', 'std']) #.loc[['Smith' , 'Doe']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting rows with filter.  Counts true's in the returned series with .sum\n",
    "filt = df['last'] == 'Doe'\n",
    "df.loc[filt]['first'].str.contains('Jane').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But fora group need to .apply the function to all the group's series \n",
    "grp_last['first'].apply(lambda x: x.str.contains('n').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the percentage with an n in their first name and group by surname\n",
    "\n",
    "# Create a series of the number of people with each surname\n",
    "surname_count = df['last'].value_counts()\n",
    "surname_count\n",
    "\n",
    "# Create a series of people with each surname, with 'n' in first name\n",
    "surname_count_with_n = grp_last['first'].apply(lambda x: x.str.contains('n').sum())\n",
    "surname_count_with_n\n",
    "\n",
    "# Merge the 2 series togther, add and calculate the percentage (answer column) and tidy up column names\n",
    "df_with_n = pd.concat([surname_count, surname_count_with_n], axis='columns', sort=False)\n",
    "df_with_n['percentage'] = df_with_n['first']/df_with_n['last']*100\n",
    "df_with_n.rename(columns={'first': 'First_with_an_n', 'last': 'Surname'}, inplace=True)\n",
    "df_with_n.sort_values('percentage', ascending=False)\n",
    "# df_with_n.loc['Smith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesson 9 Cleaning Data\n",
    "\n",
    "# Set-up some dirty data  \n",
    "people = {\n",
    "    'first': ['Corey', 'Jane', 'John', 'Chris', np.nan, None, 'NA'], \n",
    "    'last': ['Schafer', 'Doe', 'Doe', 'Schafer', np.nan, np.nan, 'Missing'], \n",
    "    'email': ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com', None, np.nan, 'Anonymous@email.com', 'NA'],\n",
    "    'age': ['33', '55', '63', '36', None, None, 'Missing']\n",
    "}\n",
    "df = pd.DataFrame(people)\n",
    "df\n",
    "# GOOD IDEA look for unique values in columns to see if you're likely to get problems \n",
    "# for i in df.columns:\n",
    "#     print(f'\\n{i}')\n",
    "#     print(df[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify na values (by getting a mask) rather than drop them with .isna\n",
    "df.isna()\n",
    "# or\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning. Replace unusual nill values across whole data frame\n",
    "# Could do all this at import time for csv pd.read_csv(XXXXX..., na_values=['NA','Missing'])\n",
    "df.replace('NA', np.nan, inplace=True)\n",
    "df.replace('Missing', np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning. Replaces NaN values with an actual value.  Most usful for NUMERIC data\n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any / all rows that aren't totally complete with .dropna & how = 'any'\n",
    "# default values are: df.dropna(axis='index', how='any')\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop incomplete columns.  Which is all of them due to row 4\n",
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that have missing data in either ('any') specified rows with how='' & subset=[]\n",
    "df.dropna(axis='index', how='any', subset=['last', 'email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify if data type is correct.  If numeric are wrong many aggrate functions won't work \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning. Casting a column to the correct data type with .astype\n",
    "# Can use .astype on whole dataframe too.\n",
    "# Use float not int, as NaN is a float.\n",
    "df['age'] = df['age'].astype(float)\n",
    "df.dtypes\n",
    "# df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesson 10 - Date Time Series\n",
    "# Can use ,format= if .to_datetime doesn't auto recognise the date / time format\n",
    "df = pd.read_csv('time_series.csv')\n",
    "df['Date']=pd.to_datetime(df['Date'], format='%Y-%m-%d %I-%p')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find day name for single cell with .day_name() method\n",
    "df.loc[0, 'Date'].day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column comtaining day name with .dt.day_name()\n",
    "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some date functions\n",
    "print(df['Date'].min())\n",
    "print(df['Date'].max())\n",
    "print(df['Date'].max() - df['Date'].min()) # Known as time delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering on date range in str converted to a datetime with .to_datetime\n",
    "filt = (df['Date'] >= pd.to_datetime('2019-01-01')) & (df['Date'] < pd.to_datetime('2020-01-01'))\n",
    "df.loc[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting date column as an index for later functions\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single value slice on index with .loc\n",
    "df.loc['2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice on index with .loc and for range :\n",
    "df.loc['2020-01':'2020-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an aggregate value (eg mean or max) of a column sliced by date \n",
    "print(  df.loc['2020-01':'2020-02']['Close'].mean() )\n",
    "print(  df.loc['2020-01-01']['High'].max()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample (downsample) a range using 'D' for day and .resample\n",
    "highs = df['High'].resample('D').max()\n",
    "highs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick line plot with mathplot & a Magic command needed for Jupyter notebook\n",
    "%matplotlib inline \n",
    "highs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample whole dataframe with single aggregation method\n",
    "df.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample whole dataframe with diferent aggregations with a map & .agg method\n",
    "df.resample('W').agg({'Close': 'mean', 'High': 'max', 'Low': 'min', 'Volume': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lesson 11: Reading and Writing to Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with csv's \n",
    "df = pd.read_csv('time_series.csv', index_col='Date') # Load in the csv\n",
    "\n",
    "filt = (df['Volume'] > 1_000_000)                           # Do some processing\n",
    "df_big_trade_days =  df.loc[filt]                           # Do some processing\n",
    "# \n",
    "df_big_trade_days.to_csv('output.csv')                      # Save as csv \n",
    "df_big_trade_days.to_csv('output.tsv', sep='\\t')            # Save as csv with tab seperators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Exel with .to_excel and read_excel\n",
    "# conda install xlwt openpyxl xlrd \n",
    "df_big_trade_days.to_excel('output.xlsx')                   # Saving a dataframe to Excel.  Can use sheet arg & row & column \n",
    "df_excel = pd.read_excel('output.xlsx' , index_col='Date')  # Loading in from Excel\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with json with .to_json and read_json\n",
    "df_big_trade_days.to_json('output.json', orient='records', lines=True)\n",
    "# Make records /list like rather than dictionary like with: orient='records' \n",
    "# Make each record a new line with lines=True' \n",
    "df_json = pd.read_json('output.json', orient='records', lines=True)\n",
    "df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with SQL\n",
    "# Set up database \n",
    "# from sqlalchemy import create_engine\n",
    "# import psycopg2\n",
    "# engine = create_engine('postgresql://dbuser:dbpass@localhost:5432/sample_db')\n",
    "# df.to_sql('sample_table', engine, if_exists='replace')\n",
    "# sql_df = pd.read_sql('sample_table', engine, index_col='Respondent')\n",
    "# sql_df = pd.read_sql_query('SELECT * FROM sample_table', engine, index_col='Respondent')\n",
    "# # sql_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can read directly from a URL\n",
    "posts_df = pd.read_json('https://raw.githubusercontent.com/CoreyMSchafer/code_snippets/master/Python/Flask_Blog/snippets/posts.json')\n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3abd6171fa1ea65bf49371a625e2f428f7c9851bddb54635de65591e57828a17"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('c3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
