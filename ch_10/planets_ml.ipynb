{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing out-of-this world data, Part 2\n",
    "Using data collected from the Open Exoplanet Catalogue database: https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue/\n",
    "\n",
    "## Data License\n",
    "Copyright (C) 2012 Hanno Rein\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this database and associated scripts (the \"Database\"), to deal in the Database without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Database, and to permit persons to whom the Database is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Database. A reference to the Database shall be included in all scientific publications that make use of the Database.\n",
    "\n",
    "THE DATABASE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE DATABASE OR THE USE OR OTHER DEALINGS IN THE DATABASE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "planets = pd.read_csv('data/planets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we completed our EDA in the [`planets_ml.ipynb`](../ch_09/planets_ml.ipynb) notebook for last chapter, we will just look at the first 5 rows to refresh our memory of the data rather than repeating the EDA here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass</th>\n",
       "      <th>description</th>\n",
       "      <th>periastrontime</th>\n",
       "      <th>semimajoraxis</th>\n",
       "      <th>discoveryyear</th>\n",
       "      <th>list</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>period</th>\n",
       "      <th>discoverymethod</th>\n",
       "      <th>lastupdate</th>\n",
       "      <th>periastron</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.400</td>\n",
       "      <td>11 Com b is a brown dwarf-mass companion to th...</td>\n",
       "      <td>2452899.60</td>\n",
       "      <td>1.290</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Confirmed planets</td>\n",
       "      <td>0.231</td>\n",
       "      <td>326.03</td>\n",
       "      <td>RV</td>\n",
       "      <td>15/09/20</td>\n",
       "      <td>94.800</td>\n",
       "      <td>11 Com b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.200</td>\n",
       "      <td>11 Ursae Minoris is a star located in the cons...</td>\n",
       "      <td>2452861.04</td>\n",
       "      <td>1.540</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Confirmed planets</td>\n",
       "      <td>0.080</td>\n",
       "      <td>516.22</td>\n",
       "      <td>RV</td>\n",
       "      <td>15/09/20</td>\n",
       "      <td>117.630</td>\n",
       "      <td>11 UMi b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.800</td>\n",
       "      <td>14 Andromedae is an evolved star in the conste...</td>\n",
       "      <td>2452861.40</td>\n",
       "      <td>0.830</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Confirmed planets</td>\n",
       "      <td>0.000</td>\n",
       "      <td>185.84</td>\n",
       "      <td>RV</td>\n",
       "      <td>15/09/20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14 And b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.975</td>\n",
       "      <td>The star 14 Herculis is only 59 light years aw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.864</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Confirmed planets</td>\n",
       "      <td>0.359</td>\n",
       "      <td>1766.00</td>\n",
       "      <td>RV</td>\n",
       "      <td>15/09/21</td>\n",
       "      <td>22.230</td>\n",
       "      <td>14 Her b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.679</td>\n",
       "      <td>14 Her c is the second companion in the system...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.037</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Controversial</td>\n",
       "      <td>0.184</td>\n",
       "      <td>9886.00</td>\n",
       "      <td>RV</td>\n",
       "      <td>15/09/21</td>\n",
       "      <td>189.076</td>\n",
       "      <td>14 Her c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mass                                        description  periastrontime  \\\n",
       "0  19.400  11 Com b is a brown dwarf-mass companion to th...      2452899.60   \n",
       "1  11.200  11 Ursae Minoris is a star located in the cons...      2452861.04   \n",
       "2   4.800  14 Andromedae is an evolved star in the conste...      2452861.40   \n",
       "3   4.975  The star 14 Herculis is only 59 light years aw...             NaN   \n",
       "4   7.679  14 Her c is the second companion in the system...             NaN   \n",
       "\n",
       "   semimajoraxis  discoveryyear               list  eccentricity   period  \\\n",
       "0          1.290         2008.0  Confirmed planets         0.231   326.03   \n",
       "1          1.540         2009.0  Confirmed planets         0.080   516.22   \n",
       "2          0.830         2008.0  Confirmed planets         0.000   185.84   \n",
       "3          2.864         2002.0  Confirmed planets         0.359  1766.00   \n",
       "4          9.037         2006.0      Controversial         0.184  9886.00   \n",
       "\n",
       "  discoverymethod lastupdate  periastron      name  \n",
       "0              RV   15/09/20      94.800  11 Com b  \n",
       "1              RV   15/09/20     117.630  11 UMi b  \n",
       "2              RV   15/09/20       0.000  14 And b  \n",
       "3              RV   15/09/21      22.230  14 Her b  \n",
       "4              RV   15/09/21     189.076  14 Her c  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "As in chapter 9, we will be predicting the length of a year (period) on our planets data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = planets[\n",
    "    ['semimajoraxis', 'period', 'mass', 'eccentricity']\n",
    "].dropna()\n",
    "planets_X = data[['semimajoraxis', 'mass', 'eccentricity']]\n",
    "# planets_y = data.period\n",
    "planets_y = data['period']\n",
    "\n",
    "pl_X_train, pl_X_test, pl_y_train, pl_y_test = train_test_split(\n",
    "    planets_X, planets_y, test_size=0.25, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression to Predict Year Length from Chapter 9\n",
    "This was the result from chapter 9 for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        LinearRegression\n",
      "\u001b[0;31mString form:\u001b[0m LinearRegression()\n",
      "\u001b[0;31mFile:\u001b[0m        ~/opt/miniconda3/envs/hands/lib/python3.7/site-packages/sklearn/linear_model/_base.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Ordinary least squares Linear Regression.\n",
      "\n",
      "LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      "to minimize the residual sum of squares between the observed targets in\n",
      "the dataset, and the targets predicted by the linear approximation.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "fit_intercept : bool, default=True\n",
      "    Whether to calculate the intercept for this model. If set\n",
      "    to False, no intercept will be used in calculations\n",
      "    (i.e. data is expected to be centered).\n",
      "\n",
      "normalize : bool, default=False\n",
      "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "    If True, the regressors X will be normalized before regression by\n",
      "    subtracting the mean and dividing by the l2-norm.\n",
      "    If you wish to standardize, please use\n",
      "    :class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\n",
      "    an estimator with ``normalize=False``.\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If True, X will be copied; else, it may be overwritten.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of jobs to use for the computation. This will only provide\n",
      "    speedup for n_targets > 1 and sufficient large problems.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      "    Estimated coefficients for the linear regression problem.\n",
      "    If multiple targets are passed during the fit (y 2D), this\n",
      "    is a 2D array of shape (n_targets, n_features), while if only\n",
      "    one target is passed, this is a 1D array of length n_features.\n",
      "\n",
      "rank_ : int\n",
      "    Rank of matrix `X`. Only available when `X` is dense.\n",
      "\n",
      "singular_ : array of shape (min(X, y),)\n",
      "    Singular values of `X`. Only available when `X` is dense.\n",
      "\n",
      "intercept_ : float or array of shape (n_targets,)\n",
      "    Independent term in the linear model. Set to 0.0 if\n",
      "    `fit_intercept = False`.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "sklearn.linear_model.Ridge : Ridge regression addresses some of the\n",
      "    problems of Ordinary Least Squares by imposing a penalty on the\n",
      "    size of the coefficients with l2 regularization.\n",
      "sklearn.linear_model.Lasso : The Lasso is a linear model that estimates\n",
      "    sparse coefficients with l1 regularization.\n",
      "sklearn.linear_model.ElasticNet : Elastic-Net is a linear regression\n",
      "    model trained with both l1 and l2 -norm regularization of the\n",
      "    coefficients.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "From the implementation point of view, this is just plain Ordinary\n",
      "Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.linear_model import LinearRegression\n",
      ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
      ">>> reg = LinearRegression().fit(X, y)\n",
      ">>> reg.score(X, y)\n",
      "1.0\n",
      ">>> reg.coef_\n",
      "array([1., 2.])\n",
      ">>> reg.intercept_\n",
      "3.0000...\n",
      ">>> reg.predict(np.array([[3, 5]]))\n",
      "array([16.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression().fit(pl_X_train, pl_y_train)\n",
    "preds = lm.predict(pl_X_test)\n",
    "# lm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean absolute error (MAE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369.4418170735335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(pl_y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with `GridSearchCV`\n",
    "Note that `GridSearchCV` will try to maximize the scores, but we are using error metrics for all but $R^2$, so we use the versions marked with `neg_` as a prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "search_space = {\n",
    "    'scale__with_mean': [True, False], \n",
    "    'scale__with_std': [True, False],\n",
    "    'lr__fit_intercept': [True, False], \n",
    "    'lr__normalize': [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model_pipeline, search_space, cv=5,\n",
    "    scoring={\n",
    "        'r_squared': 'r2', \n",
    "        'mse': 'neg_mean_squared_error', \n",
    "        'mae': 'neg_mean_absolute_error',\n",
    "        'rmse': make_scorer(lambda x, y: -np.sqrt(mean_squared_error(x, y)))\n",
    "    }, refit='mae'\n",
    ").fit(pl_X_train, pl_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the best score from the cross validation and the best hyperparameters in the search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters (CV score=%.2f):\\n%s' % (\n",
    "    grid.best_score_, grid.best_params_\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reduced our MAE by over 120 Earth days (compared to chapter 9's model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(pl_y_test, grid.predict(pl_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can a decision tree tell us what features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=0).fit(pl_X_train, pl_y_train)\n",
    "[(col, coef) for col, coef in zip(\n",
    "    pl_X_train.columns, dt.feature_importances_\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the decisions the tree is making:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "graphviz.Source(export_graphviz(\n",
    "    DecisionTreeRegressor(\n",
    "        max_depth=4, random_state=0\n",
    "    ).fit(pl_X_train, pl_y_train),\n",
    "    feature_names=pl_X_train.columns\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "Ridge (L2) and LASSO (L1) are terms we can add to regression to penalize large coefficients. L2 uses squared coefficients and L1 uses the absolute value. LASSO tends to drive coeffiecients to zero and is therefore used for feature selection. We can combine the two in an elastic net. These help to reduce overfitting. Check the documentation for parameters that can be tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "ridge, lasso, elastic = Ridge(), Lasso(), ElasticNet()\n",
    "\n",
    "for model in [ridge, lasso, elastic]:\n",
    "    model.fit(pl_X_train, pl_y_train)\n",
    "    print(\n",
    "        f'{model.__class__.__name__}: '\n",
    "        f'{model.score(pl_X_test, pl_y_test):.4}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "        <a href=\"../../ch_09/planets_ml.ipynb\">\n",
    "            <button>&#8592; Chapter 9</button>\n",
    "        </a>\n",
    "        <a href=\"./red_wine.ipynb\">\n",
    "            <button>Red Wine</button>\n",
    "        </a>\n",
    "        <a href=\"./wine.ipynb\">\n",
    "            <button>Red + White Wine</button>\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../../solutions/ch_10/exercise_1.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../ch_11/1-EDA_unlabeled_data.ipynb\">\n",
    "            <button>Chapter 11 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('hands')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c8fc2cc835af1332d2c9df072a7e877b9e80a5bdc9d11986871d05ab640c283"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
