{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Time Series Data\n",
    "\n",
    "## About the Data\n",
    "In this notebook, we will be working with 5 datasets:\n",
    "- (CSV) Facebook's stock price daily throughout 2018 (obtained using the [`stock_analysis` package](https://github.com/stefmolin/stock-analysis)).\n",
    "- (CSV) Facebook's OHLC stock data from May 20, 2019 - May 24, 2019 per minute from [Nasdaq.com](https://old.nasdaq.com/symbol/fb/interactive-chart).\n",
    "- (CSV) melted stock data for Facebook from May 20, 2019 - May 24, 2019 per minute from [Nasdaq.com](https://old.nasdaq.com/symbol/fb/interactive-chart).\n",
    "- (DB) stock opening prices by the minute for Apple from May 20, 2019 - May 24, 2019 altered to have seconds in the time from [Nasdaq.com](https://old.nasdaq.com/symbol/aapl/interactive-chart).\n",
    "- (DB) stock opening prices by the minute for Facebook from May 20, 2019 - May 24, 2019 from [Nasdaq.com](https://old.nasdaq.com/symbol/fb/interactive-chart).\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trading_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>177.68</td>\n",
       "      <td>181.58</td>\n",
       "      <td>177.5500</td>\n",
       "      <td>181.42</td>\n",
       "      <td>18151903</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>181.88</td>\n",
       "      <td>184.78</td>\n",
       "      <td>181.3300</td>\n",
       "      <td>184.67</td>\n",
       "      <td>16886563</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>184.90</td>\n",
       "      <td>186.21</td>\n",
       "      <td>184.0996</td>\n",
       "      <td>184.33</td>\n",
       "      <td>13880896</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>185.59</td>\n",
       "      <td>186.90</td>\n",
       "      <td>184.9300</td>\n",
       "      <td>186.85</td>\n",
       "      <td>13574535</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>187.20</td>\n",
       "      <td>188.90</td>\n",
       "      <td>186.3300</td>\n",
       "      <td>188.28</td>\n",
       "      <td>17994726</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open    high       low   close    volume trading_volume\n",
       "date                                                                 \n",
       "2018-01-02  177.68  181.58  177.5500  181.42  18151903            low\n",
       "2018-01-03  181.88  184.78  181.3300  184.67  16886563            low\n",
       "2018-01-04  184.90  186.21  184.0996  184.33  13880896            low\n",
       "2018-01-05  185.59  186.90  184.9300  186.85  13574535            low\n",
       "2018-01-08  187.20  188.90  186.3300  188.28  17994726            low"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fb = pd.read_csv('data/fb_2018.csv', index_col='date', parse_dates=True).assign(\n",
    "    trading_volume=lambda x: pd.cut(x.volume, bins=3, labels=['low', 'med', 'high'])\n",
    ")\n",
    "fb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-based selection and filtering\n",
    "Remember, when we have an index of type `DatetimeIndex`, we can use datetime slicing. We can provide a range of dates. We only get three days back because the stock market is closed on the weekends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trading_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-11</th>\n",
       "      <td>150.13</td>\n",
       "      <td>154.81</td>\n",
       "      <td>149.1600</td>\n",
       "      <td>153.35</td>\n",
       "      <td>35338901</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-12</th>\n",
       "      <td>156.73</td>\n",
       "      <td>156.89</td>\n",
       "      <td>151.2998</td>\n",
       "      <td>153.74</td>\n",
       "      <td>25293492</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>153.32</td>\n",
       "      <td>155.57</td>\n",
       "      <td>152.5500</td>\n",
       "      <td>153.52</td>\n",
       "      <td>15433521</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open    high       low   close    volume trading_volume\n",
       "date                                                                 \n",
       "2018-10-11  150.13  154.81  149.1600  153.35  35338901            low\n",
       "2018-10-12  156.73  156.89  151.2998  153.74  25293492            low\n",
       "2018-10-15  153.32  155.57  152.5500  153.52  15433521            low"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb['2018-10-11':'2018-10-15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select ranges of months and quarters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.loc['2018-q1'].equals(fb['2018-01':'2018-03'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `first()` method will give us a specified length of time from the beginning of the time series. Here, we ask for a week. January 1, 2018 was a holidayâ€”meaning the market was closed. It was also a Monday, so the week here is only four days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trading_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>177.68</td>\n",
       "      <td>181.58</td>\n",
       "      <td>177.5500</td>\n",
       "      <td>181.42</td>\n",
       "      <td>18151903</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>181.88</td>\n",
       "      <td>184.78</td>\n",
       "      <td>181.3300</td>\n",
       "      <td>184.67</td>\n",
       "      <td>16886563</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>184.90</td>\n",
       "      <td>186.21</td>\n",
       "      <td>184.0996</td>\n",
       "      <td>184.33</td>\n",
       "      <td>13880896</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>185.59</td>\n",
       "      <td>186.90</td>\n",
       "      <td>184.9300</td>\n",
       "      <td>186.85</td>\n",
       "      <td>13574535</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open    high       low   close    volume trading_volume\n",
       "date                                                                 \n",
       "2018-01-02  177.68  181.58  177.5500  181.42  18151903            low\n",
       "2018-01-03  181.88  184.78  181.3300  184.67  16886563            low\n",
       "2018-01-04  184.90  186.21  184.0996  184.33  13880896            low\n",
       "2018-01-05  185.59  186.90  184.9300  186.85  13574535            low"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.first('1W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `last()` method will take from the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trading_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>134.45</td>\n",
       "      <td>134.64</td>\n",
       "      <td>129.95</td>\n",
       "      <td>131.09</td>\n",
       "      <td>24625308</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open    high     low   close    volume trading_volume\n",
       "date                                                               \n",
       "2018-12-31  134.45  134.64  129.95  131.09  24625308            low"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb.last('1W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we reindexed the Facebook stock data to include all dates for 2018. We would have null entries for January 1st:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_reindexed = fb.reindex(pd.date_range('2018-01-01', '2018-12-31', freq='D'))\n",
    "fb_reindexed.first('1D').isna().squeeze().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `first_valid_index()` to give us the index of the first non-null entry in our data, which is the first day the market was open in Q1 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-01-02 00:00:00', freq='D')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_reindexed.loc['2018-Q1'].first_valid_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, we can use `last_valid_index()` to get the last entry of non-null data. For Q1 2018, this is March 29th:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-03-29 00:00:00', freq='D')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_reindexed.loc['2018-Q1'].last_valid_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `asof()` to find the last non-null data before the point we are looking for. If we ask for March 31st, we will get the data from the index we got from `fb_reindexed.loc['2018-Q1'].last_valid_index()`, which was March 29th. Note that this works regardless of whether we reindexed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open                   155.15\n",
       "high                   161.42\n",
       "low                    154.14\n",
       "close                  159.79\n",
       "volume            59434293.00\n",
       "trading_volume            low\n",
       "Name: 2018-03-31 00:00:00, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_reindexed.asof('2018-03-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next few examples, we need datetimes, so we will read in the stock data per minute file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-20 09:30:00</th>\n",
       "      <td>181.6200</td>\n",
       "      <td>181.6200</td>\n",
       "      <td>181.6200</td>\n",
       "      <td>181.6200</td>\n",
       "      <td>159049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-20 09:31:00</th>\n",
       "      <td>182.6100</td>\n",
       "      <td>182.6100</td>\n",
       "      <td>182.6100</td>\n",
       "      <td>182.6100</td>\n",
       "      <td>468017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-20 09:32:00</th>\n",
       "      <td>182.7458</td>\n",
       "      <td>182.7458</td>\n",
       "      <td>182.7458</td>\n",
       "      <td>182.7458</td>\n",
       "      <td>97258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-20 09:33:00</th>\n",
       "      <td>182.9500</td>\n",
       "      <td>182.9500</td>\n",
       "      <td>182.9500</td>\n",
       "      <td>182.9500</td>\n",
       "      <td>43961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-20 09:34:00</th>\n",
       "      <td>183.0600</td>\n",
       "      <td>183.0600</td>\n",
       "      <td>183.0600</td>\n",
       "      <td>183.0600</td>\n",
       "      <td>79562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close    volume\n",
       "date                                                                 \n",
       "2019-05-20 09:30:00  181.6200  181.6200  181.6200  181.6200  159049.0\n",
       "2019-05-20 09:31:00  182.6100  182.6100  182.6100  182.6100  468017.0\n",
       "2019-05-20 09:32:00  182.7458  182.7458  182.7458  182.7458   97258.0\n",
       "2019-05-20 09:33:00  182.9500  182.9500  182.9500  182.9500   43961.0\n",
       "2019-05-20 09:34:00  183.0600  183.0600  183.0600  183.0600   79562.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_per_minute = pd.read_csv(\n",
    "    'data/fb_week_of_may_20_per_minute.csv', index_col='date', parse_dates=True, \n",
    "    date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d %H-%M')\n",
    ")\n",
    "\n",
    "stock_data_per_minute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a `Grouper` object to roll up our data to the daily level along with `first` and `last`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-20</th>\n",
       "      <td>181.62</td>\n",
       "      <td>184.1800</td>\n",
       "      <td>181.6200</td>\n",
       "      <td>182.72</td>\n",
       "      <td>10044838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-21</th>\n",
       "      <td>184.53</td>\n",
       "      <td>185.5800</td>\n",
       "      <td>183.9700</td>\n",
       "      <td>184.82</td>\n",
       "      <td>7198405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-22</th>\n",
       "      <td>184.81</td>\n",
       "      <td>186.5603</td>\n",
       "      <td>184.0120</td>\n",
       "      <td>185.32</td>\n",
       "      <td>8412433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23</th>\n",
       "      <td>182.50</td>\n",
       "      <td>183.7300</td>\n",
       "      <td>179.7559</td>\n",
       "      <td>180.87</td>\n",
       "      <td>12479171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24</th>\n",
       "      <td>182.33</td>\n",
       "      <td>183.5227</td>\n",
       "      <td>181.0400</td>\n",
       "      <td>181.06</td>\n",
       "      <td>7686030.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open      high       low   close      volume\n",
       "date                                                      \n",
       "2019-05-20  181.62  184.1800  181.6200  182.72  10044838.0\n",
       "2019-05-21  184.53  185.5800  183.9700  184.82   7198405.0\n",
       "2019-05-22  184.81  186.5603  184.0120  185.32   8412433.0\n",
       "2019-05-23  182.50  183.7300  179.7559  180.87  12479171.0\n",
       "2019-05-24  182.33  183.5227  181.0400  181.06   7686030.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_per_minute.groupby(pd.Grouper(freq='1D')).agg({\n",
    "    'open': 'first',\n",
    "    'high': 'max', \n",
    "    'low': 'min', \n",
    "    'close': 'last', \n",
    "    'volume': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `at_time()` method allows us to pull out all datetimes that match a certain time. Here, we can grab all the rows from the time the stock market opens (9:30 AM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-20 09:30:00</th>\n",
       "      <td>181.62</td>\n",
       "      <td>181.62</td>\n",
       "      <td>181.62</td>\n",
       "      <td>181.62</td>\n",
       "      <td>159049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-21 09:30:00</th>\n",
       "      <td>184.53</td>\n",
       "      <td>184.53</td>\n",
       "      <td>184.53</td>\n",
       "      <td>184.53</td>\n",
       "      <td>58171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-22 09:30:00</th>\n",
       "      <td>184.81</td>\n",
       "      <td>184.81</td>\n",
       "      <td>184.81</td>\n",
       "      <td>184.81</td>\n",
       "      <td>41585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23 09:30:00</th>\n",
       "      <td>182.50</td>\n",
       "      <td>182.50</td>\n",
       "      <td>182.50</td>\n",
       "      <td>182.50</td>\n",
       "      <td>121930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24 09:30:00</th>\n",
       "      <td>182.33</td>\n",
       "      <td>182.33</td>\n",
       "      <td>182.33</td>\n",
       "      <td>182.33</td>\n",
       "      <td>52681.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close    volume\n",
       "date                                                         \n",
       "2019-05-20 09:30:00  181.62  181.62  181.62  181.62  159049.0\n",
       "2019-05-21 09:30:00  184.53  184.53  184.53  184.53   58171.0\n",
       "2019-05-22 09:30:00  184.81  184.81  184.81  184.81   41585.0\n",
       "2019-05-23 09:30:00  182.50  182.50  182.50  182.50  121930.0\n",
       "2019-05-24 09:30:00  182.33  182.33  182.33  182.33   52681.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_per_minute.at_time('9:30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `between_time()` to grab data for the last two minutes of trading daily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-20 15:59:00</th>\n",
       "      <td>182.915</td>\n",
       "      <td>182.915</td>\n",
       "      <td>182.915</td>\n",
       "      <td>182.915</td>\n",
       "      <td>134569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-20 16:00:00</th>\n",
       "      <td>182.720</td>\n",
       "      <td>182.720</td>\n",
       "      <td>182.720</td>\n",
       "      <td>182.720</td>\n",
       "      <td>1113672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-21 15:59:00</th>\n",
       "      <td>184.840</td>\n",
       "      <td>184.840</td>\n",
       "      <td>184.840</td>\n",
       "      <td>184.840</td>\n",
       "      <td>61606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-21 16:00:00</th>\n",
       "      <td>184.820</td>\n",
       "      <td>184.820</td>\n",
       "      <td>184.820</td>\n",
       "      <td>184.820</td>\n",
       "      <td>801080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-22 15:59:00</th>\n",
       "      <td>185.290</td>\n",
       "      <td>185.290</td>\n",
       "      <td>185.290</td>\n",
       "      <td>185.290</td>\n",
       "      <td>96099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-22 16:00:00</th>\n",
       "      <td>185.320</td>\n",
       "      <td>185.320</td>\n",
       "      <td>185.320</td>\n",
       "      <td>185.320</td>\n",
       "      <td>1220993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23 15:59:00</th>\n",
       "      <td>180.720</td>\n",
       "      <td>180.720</td>\n",
       "      <td>180.720</td>\n",
       "      <td>180.720</td>\n",
       "      <td>109648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23 16:00:00</th>\n",
       "      <td>180.870</td>\n",
       "      <td>180.870</td>\n",
       "      <td>180.870</td>\n",
       "      <td>180.870</td>\n",
       "      <td>1329217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24 15:59:00</th>\n",
       "      <td>181.070</td>\n",
       "      <td>181.070</td>\n",
       "      <td>181.070</td>\n",
       "      <td>181.070</td>\n",
       "      <td>52994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24 16:00:00</th>\n",
       "      <td>181.060</td>\n",
       "      <td>181.060</td>\n",
       "      <td>181.060</td>\n",
       "      <td>181.060</td>\n",
       "      <td>764906.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close     volume\n",
       "date                                                              \n",
       "2019-05-20 15:59:00  182.915  182.915  182.915  182.915   134569.0\n",
       "2019-05-20 16:00:00  182.720  182.720  182.720  182.720  1113672.0\n",
       "2019-05-21 15:59:00  184.840  184.840  184.840  184.840    61606.0\n",
       "2019-05-21 16:00:00  184.820  184.820  184.820  184.820   801080.0\n",
       "2019-05-22 15:59:00  185.290  185.290  185.290  185.290    96099.0\n",
       "2019-05-22 16:00:00  185.320  185.320  185.320  185.320  1220993.0\n",
       "2019-05-23 15:59:00  180.720  180.720  180.720  180.720   109648.0\n",
       "2019-05-23 16:00:00  180.870  180.870  180.870  180.870  1329217.0\n",
       "2019-05-24 15:59:00  181.070  181.070  181.070  181.070    52994.0\n",
       "2019-05-24 16:00:00  181.060  181.060  181.060  181.060   764906.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_per_minute.between_time('15:59', '16:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, are more shares traded within the first 30 minutes of trading or in the last 30 minutes? We can combine `between_time()` with `group_by()` and `filter()` from the [`3-aggregations.ipynb`](./3-aggregations.ipynb) notebook to answer this question. For the week in question, more are traded on average around opening time than closing time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18592.967741935485"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares_traded_in_first_30_min = stock_data_per_minute\\\n",
    "    .between_time('9:30', '10:00')\\\n",
    "    .groupby(pd.Grouper(freq='1D'))\\\n",
    "    .filter(lambda x: (x.volume > 0).all())\\\n",
    "    .volume.mean()\n",
    "\n",
    "shares_traded_in_last_30_min = stock_data_per_minute\\\n",
    "    .between_time('15:30', '16:00')\\\n",
    "    .groupby(pd.Grouper(freq='1D'))\\\n",
    "    .filter(lambda x: (x.volume > 0).all())\\\n",
    "    .volume.mean()\n",
    "\n",
    "shares_traded_in_first_30_min - shares_traded_in_last_30_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where time doesn't matter, we can normalize the times to midnight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    dict(before=stock_data_per_minute.index, after=stock_data_per_minute.index.normalize())\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can also use `normalize()` on a `Series` object after accessing the `dt` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_per_minute.index.to_series().dt.normalize().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting for lagged data\n",
    "We can use `shift()` to create lagged data. By default, the shift will be one period. For example, we can use `shift()` to create a new column that indicates the previous day's closing price. From this new column, we can calculate the price change due to after-hours trading (after the close one day right up to the open the following day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.assign(\n",
    "    prior_close=lambda x: x.close.shift(),\n",
    "    after_hours_change_in_price=lambda x: x.open - x.prior_close,\n",
    "    abs_change=lambda x: x.after_hours_change_in_price.abs()\n",
    ").nlargest(5, 'abs_change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the goal is to to add/subtract time, we can use `pd.Timedelta` objects instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range('2018-01-01', freq='D', periods=5) + pd.Timedelta('9 hours 30 minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differenced data\n",
    "Using the `diff()` method is a quick way to calculate the difference between the data and a lagged version of itself. By default, it will yield the result of `data - data.shift()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    fb.drop(columns='trading_volume') \n",
    "    - fb.drop(columns='trading_volume').shift()\n",
    ").equals(\n",
    "    fb.drop(columns='trading_volume').diff()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to see how Facebook stock changed day-over-day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.drop(columns='trading_volume').diff().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the number of periods, can be any positive or negative integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.drop(columns='trading_volume').diff(-3).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "Sometimes the data is at a granularity that isn't conducive to our analysis. Consider the case where we have data per minute for the full year of 2018. Let's see what happens if we try to plot this, and then look at the daily aggregation of this data.\n",
    "\n",
    "*Plotting will be covered next chapter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_aids.misc_viz import resampling_example\n",
    "resampling_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot on the left has so much data we can't see anything. However, when we aggregate to the daily totals, we see the data. We can alter the granularity of the data we are working with using resampling. Recall our minute-by-minute stock data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_per_minute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can resample this to get to a daily frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_per_minute.resample('1D').agg({\n",
    "    'open': 'first',\n",
    "    'high': 'max', \n",
    "    'low': 'min', \n",
    "    'close': 'last', \n",
    "    'volume': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can downsample to quarterly data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.resample('Q').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `apply()`. Here, we show the quarterly change from start to end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.drop(columns='trading_volume').resample('Q').apply(\n",
    "    lambda x: x.last('1D').values - x.first('1D').values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following melted stock data by the minute. We don't see the OHLC data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_stock_data = pd.read_csv('data/melted_stock_data.csv', index_col='date', parse_dates=True)\n",
    "melted_stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `ohlc()` method after resampling to recover the OHLC columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_stock_data.resample('1D').ohlc()['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can upsample to increase the granularity. Note this will introduce `NaN` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.resample('6H').asfreq().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to handle these `NaN` values. We can forward-fill with `pad()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.resample('6H').pad().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a specific value or a method with `fillna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.resample('6H').fillna('nearest').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `asfreq()` and `assign()` to specify the action per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.resample('6H').asfreq().assign(\n",
    "    volume=lambda x: x.volume.fillna(0), # put 0 when market is closed\n",
    "    close=lambda x: x.close.fillna(method='ffill'), # carry forward\n",
    "    # take the closing price if these aren't available\n",
    "    open=lambda x: x.open.combine_first(x.close),\n",
    "    high=lambda x: x.high.combine_first(x.close),\n",
    "    low=lambda x: x.low.combine_first(x.close)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging\n",
    "We saw merging examples the [`1-querying_and_merging.ipynb`](./1-querying_and_merging.ipynb) notebook. However, they all matched based on keys. With time series, it is possible that they are so granular that we never have the same time for multiple entries. Let's work with some stock data at different granularities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "with sqlite3.connect('data/stocks.db') as connection:\n",
    "    fb_prices = pd.read_sql(\n",
    "        'SELECT * FROM fb_prices', connection, \n",
    "        index_col='date', parse_dates=['date']\n",
    "    )\n",
    "    aapl_prices = pd.read_sql(\n",
    "        'SELECT * FROM aapl_prices', connection, \n",
    "        index_col='date', parse_dates=['date']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Facebook prices are at the minute granularity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_prices.index.second.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the Apple prices have information for the second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_prices.index.second.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform an *as of* merge to try to line these up the best we can. We specify how to handle the mismatch with the `direction` and `tolerance` parameters. We will fill in with the `direction` of `nearest` and a `tolerance` of 30 seconds. This will place the Apple data with the minute that it is closest to, so 9:31:52 will go with 9:32 and 9:37:07 will go with 9:37. Since the times are on the index, we pass in `left_index` and `right_index`, as we did with `merge()` earlier this chapter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge_asof(\n",
    "    fb_prices, aapl_prices, \n",
    "    left_index=True, right_index=True, # datetimes are in the index\n",
    "    # merge with nearest minute\n",
    "    direction='nearest', tolerance=pd.Timedelta(30, unit='s')\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't want to lose the seconds information with the Apple data, we can use `pd.merge_ordered()` instead, which will interleave the two. Note this is an outer join by default (`how` parameter). The only catch here is that we need to reset the index in order to join on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge_ordered(\n",
    "    fb_prices.reset_index(), aapl_prices.reset_index()\n",
    ").set_index('date').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a `fill_method` to handle `NaN` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge_ordered(\n",
    "    fb_prices.reset_index(), aapl_prices.reset_index(),\n",
    "    fill_method='ffill'\n",
    ").set_index('date').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use `fillna()`.\n",
    "\n",
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "         <a href=\"./3-aggregations.ipynb\">\n",
    "        <button>&#8592; Previous Notebook</button>\n",
    "    </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../../solutions/ch_04/solutions.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../ch_05/1-introducing_matplotlib.ipynb\">\n",
    "            <button>Chapter 5 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c8fc2cc835af1332d2c9df072a7e877b9e80a5bdc9d11986871d05ab640c283"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('hands')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
